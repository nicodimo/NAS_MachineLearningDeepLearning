{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NASWOT Project8.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN4PeMoG/3NgAbZ47Hht1Bc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichelePresti/NAS_MachineLearningDeepLearning/blob/main/NASWOT_Project8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Nq2-kqUpgm"
      },
      "source": [
        "#Define Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ofIogUx_T3lD"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "max_uid = 15625\n",
        "#@title ##Configuration Info { run: \"auto\" }\n",
        "#configuration by param\n",
        "api_loading_mode = \"Lite\" #@param {type: \"string\"} [\"Lite\", \"Full\"]\n",
        "dataset = \"ImageNet16\" #@param {type:\"string\"} [\"cifar10\", \"cifar100\", \"ImageNet16\"]\n",
        "run_id =  1# @param {type:\"integer\"}\n",
        "trial =  2#@param {type:\"integer\"}\n",
        "n_random =  10#@param {type:\"integer\"}\n",
        "point = '2a' # @param ['2a', '2b']\n",
        "imagenet_path = 'Use only if dataset=Imagenet16' #@param{type:\"string\"}\n",
        "use_default_path = True #@param{type:\"boolean\"}\n",
        "n_evolution = 2#@param{type: \"integer\"}\n",
        "n_arch_distance = 2#@param{type: \"integer\"}\n",
        "n_survivor = 1#@param{type:\"integer\"}\n",
        "population_size = 10#@param{type:\"integer\"}\n",
        "proxy_type = \"ReLU\" #@param {type: \"string\"} [\"ReLU\", \"SynFlow\"]\n",
        "CIFAR10 = 'cifar10'\n",
        "CIFAR100 = 'cifar100'\n",
        "IMAGENET = 'ImageNet16'\n",
        "\n",
        "\n",
        "config['score'] = 'hook_logdet'\n",
        "config['nasspace'] = 'nasbench201'\n",
        "config['augtype'] = 'none'\n",
        "config['dataset'] = dataset\n",
        "config['maxofn'] = 3\n",
        "config['batch_size'] = 128\n",
        "config['seed'] = 1\n",
        "config['run_id'] = run_id\n",
        "config['dataset_id'] = 'CIFAR10'\n",
        "config['start_uid'] = 0 \n",
        "config['stop_uid'] =  15000 \n",
        "config['trial'] = trial\n",
        "config['n_random'] = n_random\n",
        "config['point'] = point\n",
        "config['imagenet_path'] = '/content/drive/MyDrive/ImageNet16' if use_default_path else imagenet_path\n",
        "config['n_evolution'] = n_evolution\n",
        "config['n_arch_distance'] = n_arch_distance\n",
        "config['n_survivor'] = n_survivor\n",
        "config['population_size'] = population_size\n",
        "config['proxy_type'] = proxy_type\n",
        "config['api_loading_mode'] = api_loading_mode\n",
        "\n",
        "#max 15625 stop_uid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h1xetWeZeEDF",
        "outputId": "136b2560-3d04-4474-b3e9-d8ae2401e802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/MichelePresti/NAS_MachineLearningDeepLearning"
      ],
      "metadata": {
        "id": "LaYbzg0SY_rA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/NAS_MachineLearningDeepLearning/neural_model .\n",
        "!cp -r /content/NAS_MachineLearningDeepLearning/ZeroCostNas ."
      ],
      "metadata": {
        "id": "UrTGVZKZZCJn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing NasBenchAPI âœ"
      ],
      "metadata": {
        "id": "Y4fCjA8nZW7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_arch_config_by_dataset(dataset) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function return the architectures config by dataset in a pandas dataframe.\n",
        "    PARAMETERS:\n",
        "       dataset= string among [cifar10, cifar100, imaginet]\n",
        "    \"\"\"\n",
        "    if(dataset == 'cifar10'):\n",
        "        df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/nas_bench_201__CIFAR10_config.csv', header=0)\n",
        "        return df\n",
        "    if(dataset == 'cifar100'):\n",
        "      df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/nas_bench_201__CIFAR100_config.csv', header=0)\n",
        "      return df\n",
        "    if(dataset == 'ImageNet16'):\n",
        "      df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/nas_bench_201__ImageNet16_config.csv', header=0)\n",
        "      return df\n",
        "    else: \n",
        "      print('Dataset name not valid')\n",
        "      return None\n",
        "\n",
        "def get_standard_config(csv_config: pd.DataFrame) -> dict:\n",
        "    res = {}\n",
        "    res['name'] = csv_config.iloc[0]['name']\n",
        "    res['C'] = csv_config.iloc[0]['C']\n",
        "    res['N'] = csv_config.iloc[0]['N']\n",
        "    res['arch_str'] = csv_config.iloc[0]['arch_str']\n",
        "    res['num_classes'] = 1\n",
        "    return res"
      ],
      "metadata": {
        "id": "q2Mp9xSfaCnq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "if config['api_loading_mode'] == 'Lite':\n",
        "  searchspace = get_arch_config_by_dataset(config['dataset'])\n",
        "else:\n",
        "  # To be implemented the full version (Loading the NASBench201 API)\n",
        "  pass\n",
        "\n",
        "print('SearchSpace Loaded')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CjQoImMajYM",
        "outputId": "7c083a1d-f97c-4ef1-b39d-8aaf247febb2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SearchSpace Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW5ewvBLU1OE"
      },
      "source": [
        "#Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s65hVshwUCVo"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n",
        "##################################################\n",
        "import os, sys, hashlib, torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "\n",
        "def calculate_md5(fpath, chunk_size=1024 * 1024):\n",
        "    md5 = hashlib.md5()\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
        "            md5.update(chunk)\n",
        "    return md5.hexdigest()\n",
        "\n",
        "\n",
        "def check_md5(fpath, md5, **kwargs):\n",
        "    return md5 == calculate_md5(fpath, **kwargs)\n",
        "\n",
        "\n",
        "def check_integrity(fpath, md5=None):\n",
        "    if not os.path.isfile(fpath):\n",
        "        return False\n",
        "    if md5 is None:\n",
        "        return True\n",
        "    else:\n",
        "        return check_md5(fpath, md5)\n",
        "\n",
        "\n",
        "class ImageNet16(data.Dataset):\n",
        "    # http://image-net.org/download-images\n",
        "    # A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets\n",
        "    # https://arxiv.org/pdf/1707.08819.pdf\n",
        "\n",
        "    train_list = [\n",
        "        [\"train_data_batch_1\", \"27846dcaa50de8e21a7d1a35f30f0e91\"],\n",
        "        [\"train_data_batch_2\", \"c7254a054e0e795c69120a5727050e3f\"],\n",
        "        [\"train_data_batch_3\", \"4333d3df2e5ffb114b05d2ffc19b1e87\"],\n",
        "        [\"train_data_batch_4\", \"1620cdf193304f4a92677b695d70d10f\"],\n",
        "        [\"train_data_batch_5\", \"348b3c2fdbb3940c4e9e834affd3b18d\"],\n",
        "        [\"train_data_batch_6\", \"6e765307c242a1b3d7d5ef9139b48945\"],\n",
        "        [\"train_data_batch_7\", \"564926d8cbf8fc4818ba23d2faac7564\"],\n",
        "        [\"train_data_batch_8\", \"f4755871f718ccb653440b9dd0ebac66\"],\n",
        "        [\"train_data_batch_9\", \"bb6dd660c38c58552125b1a92f86b5d4\"],\n",
        "        [\"train_data_batch_10\", \"8f03f34ac4b42271a294f91bf480f29b\"],\n",
        "    ]\n",
        "    valid_list = [\n",
        "        [\"val_data\", \"3410e3017fdaefba8d5073aaa65e4bd6\"],\n",
        "    ]\n",
        "\n",
        "    def __init__(self, root, train, transform, use_num_of_class_only=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.train = train  # training set or valid set\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\"Dataset not found or corrupted.\")\n",
        "\n",
        "        if self.train:\n",
        "            downloaded_list = self.train_list\n",
        "        else:\n",
        "            downloaded_list = self.valid_list\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        # now load the picked numpy arrays\n",
        "        for i, (file_name, checksum) in enumerate(downloaded_list):\n",
        "            file_path = os.path.join(self.root, file_name)\n",
        "            # print ('Load {:}/{:02d}-th : {:}'.format(i, len(downloaded_list), file_path))\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    entry = pickle.load(f)\n",
        "                else:\n",
        "                    entry = pickle.load(f, encoding=\"latin1\")\n",
        "                self.data.append(entry[\"data\"])\n",
        "                self.targets.extend(entry[\"labels\"])\n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 16, 16)\n",
        "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "        if use_num_of_class_only is not None:\n",
        "            assert (\n",
        "                isinstance(use_num_of_class_only, int)\n",
        "                and use_num_of_class_only > 0\n",
        "                and use_num_of_class_only < 1000\n",
        "            ), \"invalid use_num_of_class_only : {:}\".format(use_num_of_class_only)\n",
        "            new_data, new_targets = [], []\n",
        "            for I, L in zip(self.data, self.targets):\n",
        "                if 1 <= L <= use_num_of_class_only:\n",
        "                    new_data.append(I)\n",
        "                    new_targets.append(L)\n",
        "            self.data = new_data\n",
        "            self.targets = new_targets\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"{name}({num} images, {classes} classes)\".format(\n",
        "            name=self.__class__.__name__,\n",
        "            num=len(self.data),\n",
        "            classes=len(set(self.targets)),\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index] - 1\n",
        "\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        root = self.root\n",
        "        for fentry in self.train_list + self.valid_list:\n",
        "            filename, md5 = fentry[0], fentry[1]\n",
        "            fpath = os.path.join(root, filename)\n",
        "            if not check_integrity(fpath, md5):\n",
        "                return False\n",
        "        return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wpvhhftTUCTS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch\n",
        "\n",
        "def get_dataset(dataset) -> DataLoader:\n",
        "    \"\"\"\n",
        "    This function return the dataset given its name in torch DataLoader format.\n",
        "    PARAMETERS:\n",
        "       dataset= string among [cifar10, cifar100, imaginet]\n",
        "    \"\"\"\n",
        "\n",
        "    if dataset == 'cifar10':\n",
        "        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
        "        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
        "        lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n",
        "              transforms.Normalize(mean, std)]\n",
        "        transform = transforms.Compose(lists)\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                                download=True, transform=transform)\n",
        "        train_dt = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'],\n",
        "                                                  shuffle=True, num_workers=2)\n",
        "    elif dataset == 'cifar100':\n",
        "        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n",
        "        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n",
        "        lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n",
        "              transforms.Normalize(mean, std)]\n",
        "        transform = transforms.Compose(lists)\n",
        "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                                download=True, transform=transform)\n",
        "        train_dt = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'],\n",
        "                                                  shuffle=True, num_workers=2)\n",
        "    elif dataset.startswith('ImageNet16'):\n",
        "        mean = [x / 255 for x in [122.68, 116.66, 104.01]]\n",
        "        std = [x / 255 for x in [63.22, 61.26, 65.09]]\n",
        "        lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(16, padding=2), transforms.ToTensor(),\n",
        "                 transforms.Normalize(mean, std)]\n",
        "        transform = transforms.Compose(lists)\n",
        "        trainset = ImageNet16(config['imagenet_path'], True, transform, 120)\n",
        "        train_dt = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'],\n",
        "                                                  shuffle=True, num_workers=2)\n",
        "    else:\n",
        "        raise TypeError(\"Unknow dataset : {:}\".format(dataset))\n",
        "\n",
        "    return train_dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xZRyJjrpUCQn"
      },
      "outputs": [],
      "source": [
        "train_dt = get_dataset(config['dataset'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "if config['dataset'] == 'cifar10':\n",
        "  df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/Cifar10Result.csv')\n",
        "elif config['dataset'] == 'cifar100':\n",
        "  df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/Cifar10Result.csv')\n",
        "else:\n",
        "  df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/ImageNet16Result.csv')\n",
        "\n",
        "try: \n",
        "  df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "except:\n",
        "  print(\"Already dropped\")\n",
        "\n",
        "acc_df = df\n"
      ],
      "metadata": {
        "id": "voCzkEUpcyDc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NASWOT Scoring Algorithm âž—"
      ],
      "metadata": {
        "id": "pz6sd7QLgbv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_batch_jacobian(net, x, target, device, args=None):\n",
        "    net.zero_grad()\n",
        "    x.requires_grad_(True)\n",
        "    y, out = net(x)\n",
        "    y.backward(torch.ones_like(y))\n",
        "    jacob = x.grad.detach()\n",
        "    return jacob, target.detach(), y.detach(), out.detach()\n",
        "\n",
        "\n",
        "def hooklogdet(K, labels=None):\n",
        "    s, ld = np.linalg.slogdet(K)\n",
        "    return ld\n",
        "\n",
        "\n",
        "def score_network(network, x, x2, target, device):\n",
        "    jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "    network(x2.to(device))\n",
        "    value = hooklogdet(network.K, target)\n",
        "    return value"
      ],
      "metadata": {
        "id": "hqNoimRxgs2U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from neural_model.neural_model import get_cell_net\n",
        "\n",
        "\"\"\"\n",
        "NAS WOT Algorithm\n",
        "\"\"\"\n",
        "\n",
        "def naswot_search(dataset, device, population, run_id=-1) -> pd.DataFrame:\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': [], 'accuracy': [], 'run_id':[]}\n",
        "    for uid in population:\n",
        "      net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "      net_config: dict = get_standard_config(net_config)\n",
        "      network = get_cell_net(net_config)\n",
        "      try:\n",
        "          start = time.time()\n",
        "          if 'hook_' in config['score']:\n",
        "\n",
        "              def counting_forward_hook(module_hook, inp, out):\n",
        "                  try:\n",
        "                      if hasattr(module_hook, 'visited_backwards') and not module_hook.visited_backwards:\n",
        "                          return\n",
        "                      if isinstance(inp, tuple):\n",
        "                          inp = inp[0]\n",
        "                      inp = inp.view(inp.size(0), -1)\n",
        "                      x = (inp > 0).float()\n",
        "                      K = x @ x.t()\n",
        "                      K2 = (1. - x) @ (1. - x.t())\n",
        "                      if hasattr(network, 'K'):\n",
        "                        network.K = network.K + K.cpu().numpy() + K2.cpu().numpy()\n",
        "                      else: \n",
        "                        network.K = K.cpu().numpy() + K2.cpu().numpy()\n",
        "                  except Exception as exception:\n",
        "                      print(exception)\n",
        "                      pass\n",
        "\n",
        "\n",
        "              def counting_backward_hook(module_hook, inp, out):\n",
        "                  module_hook.visited_backwards = True\n",
        "\n",
        "              j = []\n",
        "              for name, module in network.named_modules():\n",
        "                  j.append(name)\n",
        "                  if 'ReLU' in str(type(module)):\n",
        "                      module.register_forward_hook(counting_forward_hook)\n",
        "                      module.register_backward_hook(counting_backward_hook)\n",
        "          network = network.to(device)\n",
        "          s = []\n",
        "          for j in range(config['maxofn']):\n",
        "              data_iterator = iter(train_dt)\n",
        "              x, target = next(data_iterator)\n",
        "              x2 = torch.clone(x)\n",
        "              x2 = x2.to(device)\n",
        "              x, target = x.to(device), target.to(device)\n",
        "              jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "              if 'hook_' in config['score']:\n",
        "                  network(x2.to(device))\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "              else:\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "          acc = acc_df['valid-accuracy'].iloc[uid]\n",
        "          print(f'Score (uid {uid}): {np.mean(s)}, Accuracy: {acc}')\n",
        "          stop = time.time()\n",
        "          result['uid'].append(uid)\n",
        "          result['score'].append(np.mean(s))\n",
        "          result['accuracy'].append(acc)\n",
        "          result['run_id'].append(run_id)\n",
        "          score = np.mean(s)\n",
        "          result['elapsed_time'].append(stop-start)\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    df = pd.DataFrame.from_dict(result)\n",
        "\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': [], 'run_id':[]}\n",
        "    return df"
      ],
      "metadata": {
        "id": "Re13w9yFgr8I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Point 2 Project 8 (Random Search) âž°\n",
        "\n",
        "---\n",
        "\n",
        "A. Run 30 random search experiments on NASWOT algorithm, storing results about score, accuracy and time.\n",
        "\n",
        "B. For each of the above experiments store the best performing architecture."
      ],
      "metadata": {
        "id": "aQPU44nMdd3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ResultToSave"
      ],
      "metadata": {
        "id": "vDgpm_NRw3i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##Point 2 Configuration { run: \"auto\" }\n",
        "#configuration by param\n",
        "n_trial =  30#@param {type:\"integer\"}\n",
        "n_population =  1000#@param {type:\"integer\"}\n",
        "run_save_path = 'NASWOT_Point2a'#@param {type:\"string\"}\n",
        "best_save_path = 'NASWOT_Point2b'#@param {type:\"string\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "DTt7RgSoplBA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.environ['WANDB_CONSOLE'] = 'off'\n",
        "start = time.time()\n",
        "\n",
        "run_id = config['run_id']\n",
        "dataset = config['dataset']\n",
        "n = n_population   # N size of random sample\n",
        "trial = n_trial\n",
        "best = {}\n",
        "\n",
        "print('*******************************')\n",
        "print('Running Random Search algorithm')\n",
        "print('Parameters:')\n",
        "print(f'Dataset: {dataset}')\n",
        "print(f'Num Round: {trial}')\n",
        "print(f'Population Size: {n}')\n",
        "print('*******************************')\n",
        "\n",
        "\n",
        "for i in range(trial):\n",
        "  print(f\"Round {i}\")\n",
        "\n",
        "  # Sample N Random architectures among the searchspace\n",
        "  population = random.sample(range(max_uid), n)\n",
        "\n",
        "  # Train Population\n",
        "  trained_population = naswot_search(dataset=dataset, device=device, population=population, run_id=i)\n",
        "\n",
        "  # Save Training Results\n",
        "  trained_population.to_csv(f'ResultToSave/{run_save_path}_RunID_{i}_Dataset_{dataset}.csv')\n",
        "  trained_population.sort_values(by=['score'], ascending=False, inplace=True)\n",
        "  if len(best) > 0:\n",
        "    best: pd.DataFrame = best.append(trained_population.head(1), ignore_index=True)\n",
        "  else:\n",
        "    best = trained_population.head(config['n_survivor'])\n",
        "\n",
        "best.sort_values(by=['score'], ascending=False, inplace=True)\n",
        "best_of_all = best.head(1)\n",
        "\n",
        "best.to_csv(f'ResultToSave/{best_save_path}_Dataset_{dataset}.csv')\n",
        "stop = time.time()\n",
        "\n",
        "total_time = stop - start\n",
        "print('*****************************************************************')\n",
        "print(f'Best performing net with RandomSearch')\n",
        "print(tabulate(best_of_all, headers='keys', tablefmt='psql', showindex=False))\n",
        "print(f'Total time for search over all searchspace: {total_time}')\n",
        "print('*****************************************************************')\n"
      ],
      "metadata": {
        "id": "t-i6yAbHgWPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Results\n",
        "import pandas as pd\n",
        "import os, fnmatch\n",
        "\n",
        "dataset = config['dataset']\n",
        "def find(pattern, path):\n",
        "    result = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for name in files:\n",
        "            if fnmatch.fnmatch(name, pattern):\n",
        "                result.append(os.path.join(root, name))\n",
        "    return result\n",
        "\n",
        "files_2a = find(f'{run_save_path}_*', '/content/ResultToSave/')\n",
        "files_2b = find(f'{best_save_path}_*', '/content/ResultToSave/')\n",
        "\n",
        "df = []\n",
        "for file in files_2a:\n",
        "  tmp = pd.read_csv(file, header=0)\n",
        "  file_name = file.split('/')[-1]\n",
        "  tmp.to_csv(f'/content/drive/MyDrive/RisultatiNASWOT/{dataset}/{file_name}')\n",
        "\n",
        "for file in files_2b:\n",
        "  tmp = pd.read_csv(file, header=0)\n",
        "  file_name = file.split('/')[-1]\n",
        "  tmp.to_csv(f'/content/drive/MyDrive/RisultatiNASWOT/{dataset}/{file_name}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tghjNHiTvKem"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularized Evolution Algorithm âœ¨\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Algorithm Steps\n",
        "\n",
        "\n",
        "1.   Get N Random Architectures Called Population\n",
        "2.   Run Scoring Algorithm On Population\n",
        "3.   Take N Survivor, Choose As The Best Score\n",
        "4.   Create New Generation With Architecture At N Distance From The Survivor\n",
        "5.   Repeat From 2 For N Evolution Era"
      ],
      "metadata": {
        "id": "ETge1xVOpwhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Architecture Configuration Class\n",
        "\"\"\"\n",
        "\n",
        "class Architecture:\n",
        "    def __init__(self, arch):\n",
        "        self.architecture = arch\n",
        "        self.graph = {'0': [], '1':[], '2': []}\n",
        "        for token in arch.split('+'):\n",
        "            tmp = list(filter(lambda x: x != '', token.split('|')))\n",
        "            for x in tmp:\n",
        "                op = x.split('~')\n",
        "                self.graph[str(op[1])].append(op[0])\n",
        "            \n",
        "    def distance(self, obj):\n",
        "        differences = 0\n",
        "        if isinstance(obj, Architecture):\n",
        "            for key in self.graph.keys():\n",
        "                differences += len([i for i, j in zip(self.graph[key], obj.graph[key]) if i != j])\n",
        "            # print('DIFF:' + str(differences))\n",
        "            return differences\n",
        "        else:\n",
        "            print('Invalid Object')\n",
        "            return -1\n",
        "            \n",
        "    def print_architecture(self):\n",
        "        print(self.architecture)"
      ],
      "metadata": {
        "id": "z2G3JAktoY7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "\"\"\"\n",
        "Find all architectures with a distance n (max), the distance is calculated as Hamming Distance\n",
        "\"\"\"\n",
        "\n",
        "def find_arch_n_dist(survivors, max_dist, anchestors):\n",
        "  population = []\n",
        "  for uid in survivors['uid']:\n",
        "    net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "    net_config: dict = get_standard_config(net_config)\n",
        "    net_config = Architecture(net_config['arch_str'])\n",
        "    for id in range(0, max_uid):\n",
        "      candidate: pd.DataFrame = searchspace.loc[searchspace['uid'] == id]\n",
        "      candidate: dict = get_standard_config(candidate)\n",
        "      candidate = Architecture(candidate['arch_str'])\n",
        "      dist = net_config.distance(candidate)\n",
        "      # print('Distance: ' + str(dist))\n",
        "      # if id not in anchestors and dist <= max_dist:\n",
        "      if dist <= max_dist:\n",
        "        anchestors.append(id)\n",
        "        population.append(id)\n",
        "\n",
        "  population = random.sample(population, config['population_size']) if len(population) > config['population_size'] else []\n",
        "  population.append(*survivors['uid'])\n",
        "  return population\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "56IMvMlroY7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get N Random Samples\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = config['dataset']\n",
        "population = random.sample(range(max_uid), config['n_random'])\n",
        "trial = config['n_evolution']\n",
        "survivors = {}\n",
        "anchestors = population.copy()\n",
        "# Run Algorithm on Population\n",
        "start = time.time()\n",
        "\n",
        "print('*******************************')\n",
        "print('Running Regularized Evolution algorithm')\n",
        "print('Parameters:')\n",
        "print(f'Dataset: {dataset}')\n",
        "print(f'Num Round: {trial}')\n",
        "print(f'Scoring Algorithm: {proxy_type}')\n",
        "print('*******************************')\n",
        "for i in range(config['n_evolution']):\n",
        "  if config['proxy_type'] == 'ReLU':\n",
        "    trained_population = naswot_search(dataset, device, population)\n",
        "  else:\n",
        "    trained_population = synflow_search(dataset, device, population)\n",
        "  print('TRAINED', trained_population)\n",
        "  # Take N Survivor\n",
        "  trained_population.sort_values(by=['score'], ascending=False, inplace=True)\n",
        "  survivors = trained_population.head(config['n_survivor'])\n",
        "  print('SURVIVORS', survivors)\n",
        "  # Create New Generation\n",
        "  if i < trial:\n",
        "    population = find_arch_n_dist(survivors=survivors, max_dist=config['n_arch_distance'], anchestors=anchestors)\n",
        "  else: \n",
        "    break\n",
        "  if len(population) == 0:\n",
        "    break\n",
        "\n",
        "  print(len(population), population)\n",
        "\n",
        "stop = time.time()\n",
        "\n",
        "total_time = stop - start\n",
        "print('*****************************************************************')\n",
        "print(f'Best performing net with RandomSearch')\n",
        "print(tabulate(survivors, headers='keys', tablefmt='psql', showindex=False))\n",
        "print(f'Total time for search over all searchspace: {total_time}')\n",
        "print('*****************************************************************')\n",
        "survivors.to_csv('NASWOT_REA.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L5VGzlhvoY7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aging Evolution Algorithm (Synflow Proxy) ðŸ‘¾\n",
        "\n",
        "---\n",
        "\n",
        "### Algorithm Steps\n",
        "\n",
        "1. Get N Random Architectures Called Population\n",
        "2. Run Scoring Algorithm Based On Synflow Proxy Score\n",
        "3. Choose the best architecture and mutate in order to generate a new one\n",
        "4. Pop off the oldest architecture\n",
        "5. Repeat for N Evolution Stage"
      ],
      "metadata": {
        "id": "OZQV3CVfEwqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##Synflow Proxy Configuration { run: \"auto\" }\n",
        "#configuration by param\n",
        "n_trial =  30#@param {type:\"integer\"}\n",
        "n_population =  1000#@param {type:\"integer\"}\n",
        "save_path = 'NASWOT_AgingEvolution'#@param {type:\"string\"}\n",
        "max_trained_models=1000 #@param {type: 'integer'}\n",
        "pool_size=64 #@param {type: 'integer'}\n",
        "tournament_size=10 #@param {type: 'integer'} "
      ],
      "metadata": {
        "id": "IkQnoYqLGA8F"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Synflow NasBench201 Score\n",
        "\n",
        "import pickle\n",
        "synflow_proxy=[]\n",
        "\n",
        "file_path = ''\n",
        "dataset = config['dataset']\n",
        "\n",
        "if dataset == CIFAR10:\n",
        "  file_path = '/content/drive/MyDrive/results_release/nasbench2/nb2_cf10_seed42_dlrandom_dlinfo1_initwnone_initbnone.p'\n",
        "elif dataset == CIFAR100:\n",
        "  file_path = '/content/drive/MyDrive/results_release/nasbench2/nb2_cf100_seed42_dlrandom_dlinfo1_initwnone_initbnone.p'\n",
        "else:\n",
        "  file_path = '/content/drive/MyDrive/results_release/nasbench2/nb2_im120_seed42_dlrandom_dlinfo1_initwnone_initbnone.p'\n",
        "\n",
        "f = open(file_path,'rb')\n",
        "while(1):\n",
        "    try:\n",
        "        d = pickle.load(f)\n",
        "        synflow_proxy.append(d['logmeasures']['synflow'])\n",
        "    except EOFError:\n",
        "        break\n",
        "f.close()\n"
      ],
      "metadata": {
        "id": "CmGzNFLWLmXS"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Coded Architectures structures\n",
        "\n",
        "_opname_to_index = {\n",
        "    'none': 0,\n",
        "    'skip_connect': 1,\n",
        "    'nor_conv_1x1': 2,\n",
        "    'nor_conv_3x3': 3,\n",
        "    'avg_pool_3x3': 4\n",
        "}\n",
        "\n",
        "def get_spec_from_arch_str(arch_str):\n",
        "    nodes = arch_str.split('+')\n",
        "    nodes = [node[1:-1].split('|') for node in nodes]\n",
        "    nodes = [[op_and_input.split('~')[0]  for op_and_input in node] for node in nodes]\n",
        "\n",
        "    spec = [_opname_to_index[op] for node in nodes for op in node]\n",
        "    return spec\n",
        "\n",
        "idx_to_spec = {}\n",
        "for i in range(0, max_uid):\n",
        "    idx_to_spec[i] = get_spec_from_arch_str(searchspace.iloc[i]['arch_str'])\n",
        "\n",
        "spec_to_idx = {}\n",
        "for idx,spec in idx_to_spec.items():\n",
        "    spec_to_idx[str(spec)] = idx"
      ],
      "metadata": {
        "id": "1iCHTLVnNZfH"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import copy\n",
        "\n",
        "def random_spec():\n",
        "    return random.choice(list(idx_to_spec.values()))\n",
        "\n",
        "# def mutate_spec(old_spec):\n",
        "#     idx_to_change = random.randrange(len(old_spec))\n",
        "#     entry_to_change = old_spec[idx_to_change]\n",
        "#     possible_entries = [x for x in range(5) if x != entry_to_change]\n",
        "#     new_entry = random.choice(possible_entries)\n",
        "#     new_spec = copy.copy(old_spec)\n",
        "#     new_spec[idx_to_change] = new_entry\n",
        "#     return new_spec\n",
        "\n",
        "def mutate_spec(old_spec):\n",
        "    possible_specs = []\n",
        "    for idx_to_change in range(len(old_spec)): \n",
        "        entry_to_change = old_spec[idx_to_change]\n",
        "        possible_entries = [x for x in range(5) if x != entry_to_change]\n",
        "        for new_entry in possible_entries:\n",
        "            new_spec = copy.copy(old_spec)\n",
        "            new_spec[idx_to_change] = new_entry\n",
        "            possible_specs.append((synflow_proxy[spec_to_idx[str(new_spec)]], new_spec))\n",
        "    best_new_spec = sorted(possible_specs, key=lambda i:i[0])[-1][1]\n",
        "    if random.random() > 0.75:\n",
        "        best_new_spec = random.choice(possible_specs)[1]\n",
        "    return best_new_spec\n",
        "\n",
        "def random_combination(pool, sample_size):\n",
        "    indices = sorted(random.sample(range(len(pool)), sample_size))\n",
        "    return pool.iloc[indices]"
      ],
      "metadata": {
        "id": "pxOnX87BOWFI"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_aging_evolution(max_trained_models, tournament_size, pool):\n",
        "  epochs = 0\n",
        "  while epochs < max_trained_models:\n",
        "\n",
        "    sample = random_combination(pool, tournament_size)\n",
        "    sample.sort_values(by='score', ascending=False, inplace=True)\n",
        "    old_best = sample.head(1)\n",
        "    new_spec = mutate_spec(old_best.iloc[0]['arch'])\n",
        "    uid = spec_to_idx[str(new_spec)]\n",
        "    score = synflow_proxy[uid]\n",
        "    acc = acc_df['valid-accuracy'].iloc[uid]\n",
        "    print('NEW SPEC', new_spec)\n",
        "    # Add New Spec \n",
        "    pool = pool.append({\n",
        "        'uid': uid,\n",
        "        'arch': new_spec,\n",
        "        'score': score,\n",
        "        'acc': acc\n",
        "    }, ignore_index=True)\n",
        "    \n",
        "    # Kill Oldest Spec\n",
        "    pool = pool.iloc[1: , :]\n",
        "\n",
        "    epochs += 1\n",
        "\n",
        "  return pool"
      ],
      "metadata": {
        "id": "sioHaw5cOhrn"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def init_population(pool_size):\n",
        "  pool = {'uid': [], 'arch': [], 'score': [], 'acc': []}\n",
        "  for i in range(pool_size):\n",
        "    arch = random_spec()\n",
        "    uid = spec_to_idx[str(arch)]\n",
        "    score = synflow_proxy[uid]\n",
        "    acc = acc_df['valid-accuracy'].iloc[uid]\n",
        "    pool['uid'].append(uid)\n",
        "    pool['arch'].append(arch)\n",
        "    pool['score'].append(score)\n",
        "    pool['acc'].append(acc)\n",
        "  return pd.DataFrame(pool)"
      ],
      "metadata": {
        "id": "Hse56cR3Tjjp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aging Evolution Algorithm\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = config['dataset']\n",
        "trial = n_trial\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "print('*******************************')\n",
        "print('Running Aging Evolution algorithm')\n",
        "print('Parameters:')\n",
        "print(f'Dataset: {dataset}')\n",
        "print(f'Num Round: {trial}')\n",
        "print(f'Max Trained Models: {max_trained_models}')\n",
        "print(f'Pool Size: {pool_size}')\n",
        "print(f'Tournament Size: {tournament_size}')\n",
        "print('*******************************')\n",
        "\n",
        "# Init Population\n",
        "pool = init_population(pool_size)\n",
        "\n",
        "# print(tabulate(pool, headers='keys', tablefmt='psql', showindex=False))\n",
        "models = run_aging_evolution(max_trained_models=max_trained_models, tournament_size=tournament_size, pool=pool)\n",
        "\n",
        "models.sort_values(by='score', ascending=False, inplace=True)\n",
        "models.head(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HWyTxfUjUaH0",
        "outputId": "c05177e4-8f69-4dad-b083-8b58e800adac"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************************\n",
            "Running Aging Evolution algorithm\n",
            "Parameters:\n",
            "Dataset: ImageNet16\n",
            "Num Round: 30\n",
            "Max Trained Models: 1000\n",
            "Pool Size: 64\n",
            "Tournament Size: 10\n",
            "*******************************\n",
            "NEW SPEC [3, 1, 3, 0, 1, 3]\n",
            "NEW SPEC [3, 3, 2, 2, 2, 3]\n",
            "NEW SPEC [1, 3, 2, 2, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 1, 3]\n",
            "NEW SPEC [4, 2, 0, 3, 3, 4]\n",
            "NEW SPEC [3, 2, 4, 3, 1, 3]\n",
            "NEW SPEC [3, 4, 3, 0, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 1, 1, 0]\n",
            "NEW SPEC [3, 3, 3, 0, 1, 3]\n",
            "NEW SPEC [3, 4, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 0, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 2, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 0, 3, 3, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 2, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 0, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 0, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 4, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 1]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 0, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 0, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [1, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [2, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 2, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 2, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 4, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 4, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 4]\n",
            "NEW SPEC [3, 1, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 1, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 0, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 1, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 4]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 2, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 0, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 4, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 2]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [4, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 4, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 2, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [3, 3, 3, 4, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 1, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 0]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [0, 3, 3, 3, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 0, 3, 3]\n",
            "NEW SPEC [3, 3, 3, 3, 3, 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     uid                arch         score        acc\n",
              "64  1462  [3, 3, 3, 3, 3, 3]  2.464253e+46  23.266667"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b356313f-6aaa-498e-8762-69a8e60684cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>arch</th>\n",
              "      <th>score</th>\n",
              "      <th>acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>1462</td>\n",
              "      <td>[3, 3, 3, 3, 3, 3]</td>\n",
              "      <td>2.464253e+46</td>\n",
              "      <td>23.266667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b356313f-6aaa-498e-8762-69a8e60684cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b356313f-6aaa-498e-8762-69a8e60684cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b356313f-6aaa-498e-8762-69a8e60684cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    }
  ]
}