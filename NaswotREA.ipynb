{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichelePresti/NAS_MachineLearningDeepLearning/blob/main/NaswotREA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Nq2-kqUpgm"
      },
      "source": [
        "#Define Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ofIogUx_T3lD"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "max_uid = 15625\n",
        "#@title ##Configuration Info \n",
        "#configuration by param\n",
        "dataset = \"ImageNet16\" #@param {type:\"string\"} [\"cifar10\", \"cifar100\", \"ImageNet16\"]\n",
        "run_id =  1# @param {type:\"integer\"}\n",
        "trial =  30#@param {type:\"integer\"}\n",
        "n_random =  10#@param {type:\"integer\"}\n",
        "point = '2a' # @param ['2a', '2b']\n",
        "imagenet_path = 'Use only if dataset=Imagenet16' #@param{type:\"string\"}\n",
        "use_default_path = True #@param{type:\"boolean\"}\n",
        "n_evolution = 2#@param{type: \"integer\"}\n",
        "n_arch_distance = 6#@param{type: \"integer\"}\n",
        "n_survivor = 5#@param{type:\"integer\"}\n",
        "\n",
        "\n",
        "config['score'] = 'hook_logdet'\n",
        "config['nasspace'] = 'nasbench201'\n",
        "config['augtype'] = 'none'\n",
        "config['dataset'] = dataset\n",
        "config['maxofn'] = 3\n",
        "config['batch_size'] = 128\n",
        "config['seed'] = 1\n",
        "config['run_id'] = run_id\n",
        "config['dataset_id'] = 'CIFAR10'\n",
        "config['start_uid'] = 0 \n",
        "config['stop_uid'] =  15000 \n",
        "config['trial'] = trial\n",
        "config['n_random'] = n_random\n",
        "config['point'] = point\n",
        "config['imagenet_path'] = '/content/drive/MyDrive/ImageNet16' if use_default_path else imagenet_path\n",
        "config['n_evolution'] = n_evolution\n",
        "config['n_arch_distance'] = n_arch_distance\n",
        "config['n_survivor'] = n_survivor\n",
        "\n",
        "#max 15625 stop_uid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h1xetWeZeEDF",
        "outputId": "152cd302-370d-407d-c874-962f7a433852",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hov87k0BUwXP"
      },
      "source": [
        "#Import NAS Bench API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EVF4reTyT-_g"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/MichelePresti/NAS_MachineLearningDeepLearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OOSiDI1bUBNA"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/NAS_MachineLearningDeepLearning/neural_model ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W2IG2PhLUCaw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_arch_config_by_dataset(dataset) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    This function return the architectures config by dataset in a pandas dataframe.\n",
        "    PARAMETERS:\n",
        "       dataset= string among [cifar10, cifar100, imaginet]\n",
        "    \"\"\"\n",
        "    if(dataset == 'cifar10'):\n",
        "        df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/nas_bench_201__CIFAR10_config.csv', header=0)\n",
        "        return df\n",
        "    if(dataset == 'cifar100'):\n",
        "      df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/nas_bench_201__CIFAR100_config.csv', header=0)\n",
        "      return df\n",
        "    if(dataset == 'ImageNet16'):\n",
        "      df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/nas_bench_201__ImageNet16_config.csv', header=0)\n",
        "      return df\n",
        "    else: \n",
        "      print('Dataset name not valid')\n",
        "      return None\n",
        "\n",
        "def get_standard_config(csv_config: pd.DataFrame) -> dict:\n",
        "    res = {}\n",
        "    res['name'] = csv_config.iloc[0]['name']\n",
        "    res['C'] = csv_config.iloc[0]['C']\n",
        "    res['N'] = csv_config.iloc[0]['N']\n",
        "    res['arch_str'] = csv_config.iloc[0]['arch_str']\n",
        "    res['num_classes'] = 1\n",
        "    return res\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1oGWDNmgUCYP",
        "outputId": "efdc9527-a6dc-4bf9-a8f4-c178868b3333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0    uid        name   C  N  \\\n",
              "0               0      0  infer.tiny  16  5   \n",
              "1               1      1  infer.tiny  16  5   \n",
              "2               2      2  infer.tiny  16  5   \n",
              "3               3      3  infer.tiny  16  5   \n",
              "4               4      4  infer.tiny  16  5   \n",
              "...           ...    ...         ...  .. ..   \n",
              "15620       15620  15620  infer.tiny  16  5   \n",
              "15621       15621  15621  infer.tiny  16  5   \n",
              "15622       15622  15622  infer.tiny  16  5   \n",
              "15623       15623  15623  infer.tiny  16  5   \n",
              "15624       15624  15624  infer.tiny  16  5   \n",
              "\n",
              "                                                arch_str  num_classes  \n",
              "0      |avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~...          120  \n",
              "1      |nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~...          120  \n",
              "2      |avg_pool_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~...          120  \n",
              "3      |avg_pool_3x3~0|+|skip_connect~0|none~1|+|none...          120  \n",
              "4      |skip_connect~0|+|skip_connect~0|nor_conv_1x1~...          120  \n",
              "...                                                  ...          ...  \n",
              "15620  |none~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|skip...          120  \n",
              "15621  |avg_pool_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~...          120  \n",
              "15622  |skip_connect~0|+|nor_conv_3x3~0|nor_conv_3x3~...          120  \n",
              "15623  |none~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|avg_...          120  \n",
              "15624  |nor_conv_1x1~0|+|none~0|nor_conv_1x1~1|+|none...          120  \n",
              "\n",
              "[15625 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-292b6e55-4157-48bb-9d4b-aab8a4887f36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>uid</th>\n",
              "      <th>name</th>\n",
              "      <th>C</th>\n",
              "      <th>N</th>\n",
              "      <th>arch_str</th>\n",
              "      <th>num_classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|avg_pool_3x3~0|+|nor_conv_1x1~0|skip_connect~...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|nor_conv_3x3~0|+|nor_conv_3x3~0|avg_pool_3x3~...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|avg_pool_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|avg_pool_3x3~0|+|skip_connect~0|none~1|+|none...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|skip_connect~0|+|skip_connect~0|nor_conv_1x1~...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15620</th>\n",
              "      <td>15620</td>\n",
              "      <td>15620</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|none~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|skip...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15621</th>\n",
              "      <td>15621</td>\n",
              "      <td>15621</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|avg_pool_3x3~0|+|nor_conv_3x3~0|nor_conv_3x3~...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15622</th>\n",
              "      <td>15622</td>\n",
              "      <td>15622</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|skip_connect~0|+|nor_conv_3x3~0|nor_conv_3x3~...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15623</th>\n",
              "      <td>15623</td>\n",
              "      <td>15623</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|none~0|+|avg_pool_3x3~0|avg_pool_3x3~1|+|avg_...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15624</th>\n",
              "      <td>15624</td>\n",
              "      <td>15624</td>\n",
              "      <td>infer.tiny</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>|nor_conv_1x1~0|+|none~0|nor_conv_1x1~1|+|none...</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15625 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-292b6e55-4157-48bb-9d4b-aab8a4887f36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-292b6e55-4157-48bb-9d4b-aab8a4887f36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-292b6e55-4157-48bb-9d4b-aab8a4887f36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "searchspace = get_arch_config_by_dataset(config['dataset'])\n",
        "searchspace\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW5ewvBLU1OE"
      },
      "source": [
        "#Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s65hVshwUCVo"
      },
      "outputs": [],
      "source": [
        "##################################################\n",
        "# Copyright (c) Xuanyi Dong [GitHub D-X-Y], 2019 #\n",
        "##################################################\n",
        "import os, sys, hashlib, torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "\n",
        "if sys.version_info[0] == 2:\n",
        "    import cPickle as pickle\n",
        "else:\n",
        "    import pickle\n",
        "\n",
        "\n",
        "def calculate_md5(fpath, chunk_size=1024 * 1024):\n",
        "    md5 = hashlib.md5()\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(chunk_size), b\"\"):\n",
        "            md5.update(chunk)\n",
        "    return md5.hexdigest()\n",
        "\n",
        "\n",
        "def check_md5(fpath, md5, **kwargs):\n",
        "    return md5 == calculate_md5(fpath, **kwargs)\n",
        "\n",
        "\n",
        "def check_integrity(fpath, md5=None):\n",
        "    if not os.path.isfile(fpath):\n",
        "        return False\n",
        "    if md5 is None:\n",
        "        return True\n",
        "    else:\n",
        "        return check_md5(fpath, md5)\n",
        "\n",
        "\n",
        "class ImageNet16(data.Dataset):\n",
        "    # http://image-net.org/download-images\n",
        "    # A Downsampled Variant of ImageNet as an Alternative to the CIFAR datasets\n",
        "    # https://arxiv.org/pdf/1707.08819.pdf\n",
        "\n",
        "    train_list = [\n",
        "        [\"train_data_batch_1\", \"27846dcaa50de8e21a7d1a35f30f0e91\"],\n",
        "        [\"train_data_batch_2\", \"c7254a054e0e795c69120a5727050e3f\"],\n",
        "        [\"train_data_batch_3\", \"4333d3df2e5ffb114b05d2ffc19b1e87\"],\n",
        "        [\"train_data_batch_4\", \"1620cdf193304f4a92677b695d70d10f\"],\n",
        "        [\"train_data_batch_5\", \"348b3c2fdbb3940c4e9e834affd3b18d\"],\n",
        "        [\"train_data_batch_6\", \"6e765307c242a1b3d7d5ef9139b48945\"],\n",
        "        [\"train_data_batch_7\", \"564926d8cbf8fc4818ba23d2faac7564\"],\n",
        "        [\"train_data_batch_8\", \"f4755871f718ccb653440b9dd0ebac66\"],\n",
        "        [\"train_data_batch_9\", \"bb6dd660c38c58552125b1a92f86b5d4\"],\n",
        "        [\"train_data_batch_10\", \"8f03f34ac4b42271a294f91bf480f29b\"],\n",
        "    ]\n",
        "    valid_list = [\n",
        "        [\"val_data\", \"3410e3017fdaefba8d5073aaa65e4bd6\"],\n",
        "    ]\n",
        "\n",
        "    def __init__(self, root, train, transform, use_num_of_class_only=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.train = train  # training set or valid set\n",
        "        if not self._check_integrity():\n",
        "            raise RuntimeError(\"Dataset not found or corrupted.\")\n",
        "\n",
        "        if self.train:\n",
        "            downloaded_list = self.train_list\n",
        "        else:\n",
        "            downloaded_list = self.valid_list\n",
        "        self.data = []\n",
        "        self.targets = []\n",
        "\n",
        "        # now load the picked numpy arrays\n",
        "        for i, (file_name, checksum) in enumerate(downloaded_list):\n",
        "            file_path = os.path.join(self.root, file_name)\n",
        "            # print ('Load {:}/{:02d}-th : {:}'.format(i, len(downloaded_list), file_path))\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    entry = pickle.load(f)\n",
        "                else:\n",
        "                    entry = pickle.load(f, encoding=\"latin1\")\n",
        "                self.data.append(entry[\"data\"])\n",
        "                self.targets.extend(entry[\"labels\"])\n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 16, 16)\n",
        "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "        if use_num_of_class_only is not None:\n",
        "            assert (\n",
        "                isinstance(use_num_of_class_only, int)\n",
        "                and use_num_of_class_only > 0\n",
        "                and use_num_of_class_only < 1000\n",
        "            ), \"invalid use_num_of_class_only : {:}\".format(use_num_of_class_only)\n",
        "            new_data, new_targets = [], []\n",
        "            for I, L in zip(self.data, self.targets):\n",
        "                if 1 <= L <= use_num_of_class_only:\n",
        "                    new_data.append(I)\n",
        "                    new_targets.append(L)\n",
        "            self.data = new_data\n",
        "            self.targets = new_targets\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"{name}({num} images, {classes} classes)\".format(\n",
        "            name=self.__class__.__name__,\n",
        "            num=len(self.data),\n",
        "            classes=len(set(self.targets)),\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index] - 1\n",
        "\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _check_integrity(self):\n",
        "        root = self.root\n",
        "        for fentry in self.train_list + self.valid_list:\n",
        "            filename, md5 = fentry[0], fentry[1]\n",
        "            fpath = os.path.join(root, filename)\n",
        "            if not check_integrity(fpath, md5):\n",
        "                return False\n",
        "        return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wpvhhftTUCTS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import torch\n",
        "\n",
        "def get_dataset(dataset) -> DataLoader:\n",
        "    \"\"\"\n",
        "    This function return the dataset given its name in torch DataLoader format.\n",
        "    PARAMETERS:\n",
        "       dataset= string among [cifar10, cifar100, imaginet]\n",
        "    \"\"\"\n",
        "\n",
        "    if dataset == 'cifar10':\n",
        "        mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
        "        std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
        "        lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n",
        "              transforms.Normalize(mean, std)]\n",
        "        transform = transforms.Compose(lists)\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                                download=True, transform=transform)\n",
        "        train_dt = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'],\n",
        "                                                  shuffle=True, num_workers=2)\n",
        "    elif dataset == 'cifar100':\n",
        "        mean = [x / 255 for x in [129.3, 124.1, 112.4]]\n",
        "        std = [x / 255 for x in [68.2, 65.4, 70.4]]\n",
        "        lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4), transforms.ToTensor(),\n",
        "              transforms.Normalize(mean, std)]\n",
        "        transform = transforms.Compose(lists)\n",
        "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                                download=True, transform=transform)\n",
        "        train_dt = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'],\n",
        "                                                  shuffle=True, num_workers=2)\n",
        "    elif dataset.startswith('ImageNet16'):\n",
        "        mean = [x / 255 for x in [122.68, 116.66, 104.01]]\n",
        "        std = [x / 255 for x in [63.22, 61.26, 65.09]]\n",
        "        lists = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(16, padding=2), transforms.ToTensor(),\n",
        "                 transforms.Normalize(mean, std)]\n",
        "        transform = transforms.Compose(lists)\n",
        "        trainset = ImageNet16(config['imagenet_path'], True, transform, 120)\n",
        "        train_dt = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'],\n",
        "                                                  shuffle=True, num_workers=2)\n",
        "    else:\n",
        "        raise TypeError(\"Unknow dataset : {:}\".format(dataset))\n",
        "\n",
        "    return train_dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xZRyJjrpUCQn"
      },
      "outputs": [],
      "source": [
        "train_dt = get_dataset(config['dataset'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7EkocqlU5P7"
      },
      "source": [
        "#Define Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JqoS_7YTUCOC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_batch_jacobian(net, x, target, device, args=None):\n",
        "    net.zero_grad()\n",
        "    x.requires_grad_(True)\n",
        "    y, out = net(x)\n",
        "    y.backward(torch.ones_like(y))\n",
        "    jacob = x.grad.detach()\n",
        "    return jacob, target.detach(), y.detach(), out.detach()\n",
        "\n",
        "\n",
        "def hooklogdet(K, labels=None):\n",
        "    s, ld = np.linalg.slogdet(K)\n",
        "    return ld\n",
        "\n",
        "\n",
        "def score_network(network, x, x2, target, device):\n",
        "    jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "    network(x2.to(device))\n",
        "    value = hooklogdet(network.K, target)\n",
        "    return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLWrtL3dU7uf"
      },
      "source": [
        "#Search Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from neural_model.neural_model import get_cell_net\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm.contrib.telegram import tqdm, trange\n",
        "\n",
        "def naswot_search_n2(run_id, dataset_id, device, n):\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    n = config['n_random']\n",
        "    trial = config['trial']\n",
        "    point = config['point']\n",
        "    l = random.sample(range(max_uid), n)\n",
        "    # for uid in tqdm(l,\\\n",
        "    #    token='5374697833:AAFXE6wumxuSFFwpSzSmEQ6WL4jl8OBVOqw',\\\n",
        "    #    chat_id='142397010',\\\n",
        "    #    desc=f'result_run{run_id}_dataset{dataset_id}_point_{point}'):\n",
        "    for uid in l:\n",
        "      #i = uid-start_uid\n",
        "      net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "      net_config: dict = get_standard_config(net_config)\n",
        "      network = get_cell_net(net_config)\n",
        "      try:\n",
        "          start = time.time()\n",
        "          if 'hook_' in config['score']:\n",
        "\n",
        "              def counting_forward_hook(module_hook, inp, out):\n",
        "                  try:\n",
        "                      if hasattr(module_hook, 'visited_backwards') and not module_hook.visited_backwards:\n",
        "                          return\n",
        "                      if isinstance(inp, tuple):\n",
        "                          inp = inp[0]\n",
        "                      inp = inp.view(inp.size(0), -1)\n",
        "                      x = (inp > 0).float()\n",
        "                      K = x @ x.t()\n",
        "                      K2 = (1. - x) @ (1. - x.t())\n",
        "                      if hasattr(network, 'K'):\n",
        "                        network.K = network.K + K.cpu().numpy() + K2.cpu().numpy()\n",
        "                      else: \n",
        "                        network.K = K.cpu().numpy() + K2.cpu().numpy()\n",
        "                  except Exception as exception:\n",
        "                      print(exception)\n",
        "                      pass\n",
        "\n",
        "\n",
        "              def counting_backward_hook(module_hook, inp, out):\n",
        "                  module_hook.visited_backwards = True\n",
        "\n",
        "              j = []\n",
        "              for name, module in network.named_modules():\n",
        "                  j.append(name)\n",
        "                  if 'ReLU' in str(type(module)):\n",
        "                      module.register_forward_hook(counting_forward_hook)\n",
        "                      module.register_backward_hook(counting_backward_hook)\n",
        "\n",
        "          #print('NUM MODULES IN ARCHITECTURES', len(j))\n",
        "          # Starting score algorithm\n",
        "          network = network.to(device)\n",
        "          ## start time\n",
        "          #start = time.time()\n",
        "          random.seed(config['seed'])\n",
        "          np.random.seed(config['seed'])\n",
        "          torch.manual_seed(config['seed'])\n",
        "          s = []\n",
        "          for j in range(config['maxofn']):\n",
        "              data_iterator = iter(train_dt)\n",
        "              x, target = next(data_iterator)\n",
        "              x2 = torch.clone(x)\n",
        "              x2 = x2.to(device)\n",
        "              x, target = x.to(device), target.to(device)\n",
        "              jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "              if 'hook_' in config['score']:\n",
        "                  network(x2.to(device))\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "              else:\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "          #print(f'Score (uid {uid}): {np.mean(s)}')\n",
        "          stop = time.time()\n",
        "          result['uid'].append(uid)\n",
        "          result['score'].append(np.mean(s))\n",
        "          result['elapsed_time'].append(stop-start)\n",
        "          #print(f'Elapsed time (uid {uid}): {stop-start}')\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    df = pd.DataFrame.from_dict(result)\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    df.to_csv(f'./result_run{run_id}_{trial}_{dataset_id}.csv')\n",
        "    \n",
        "    return "
      ],
      "metadata": {
        "id": "pFNEIq332qv_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2a or 2b"
      ],
      "metadata": {
        "id": "gYVmXBTPmyCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/NAS_MachineLearningDeepLearning/Cifar10Result.csv')\n",
        "try: \n",
        "  df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "except:\n",
        "  print(\"Already dropped\")\n",
        "\n",
        "acc_df = df\n"
      ],
      "metadata": {
        "id": "9EfGHBULm08R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from neural_model.neural_model import get_cell_net\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm.contrib.telegram import tqdm, trange\n",
        "\n",
        "\n",
        "def naswot_search_n(run_id, dataset, device, n, trial):\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    n = config['n_random']\n",
        "    #trial = config['trial']\n",
        "    #random.seed(i)\n",
        "    l = random.sample(range(max_uid), n)\n",
        "    best_score, best_acc, best_net = 0, 0, 0\n",
        "    best = {}\n",
        "    best['score'] = 0\n",
        "    best['acc'] = 0\n",
        "    best['uid'] = 0\n",
        "    print(l)\n",
        "    # for uid in tqdm(l,\\\n",
        "    #    token='5374697833:AAFXE6wumxuSFFwpSzSmEQ6WL4jl8OBVOqw',\\\n",
        "    #    chat_id='142397010',\\\n",
        "    #    desc=f'result_run{run_id}_{point}_dataset{dataset_id}_'):\n",
        "    for uid in l:\n",
        "      #i = uid-start_uid\n",
        "      net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "      net_config: dict = get_standard_config(net_config)\n",
        "      network = get_cell_net(net_config)\n",
        "      try:\n",
        "          start = time.time()\n",
        "          if 'hook_' in config['score']:\n",
        "\n",
        "              def counting_forward_hook(module_hook, inp, out):\n",
        "                  try:\n",
        "                      if hasattr(module_hook, 'visited_backwards') and not module_hook.visited_backwards:\n",
        "                          return\n",
        "                      if isinstance(inp, tuple):\n",
        "                          inp = inp[0]\n",
        "                      inp = inp.view(inp.size(0), -1)\n",
        "                      x = (inp > 0).float()\n",
        "                      K = x @ x.t()\n",
        "                      K2 = (1. - x) @ (1. - x.t())\n",
        "                      if hasattr(network, 'K'):\n",
        "                        network.K = network.K + K.cpu().numpy() + K2.cpu().numpy()\n",
        "                      else: \n",
        "                        network.K = K.cpu().numpy() + K2.cpu().numpy()\n",
        "                  except Exception as exception:\n",
        "                      print(exception)\n",
        "                      pass\n",
        "\n",
        "\n",
        "              def counting_backward_hook(module_hook, inp, out):\n",
        "                  module_hook.visited_backwards = True\n",
        "\n",
        "              j = []\n",
        "              for name, module in network.named_modules():\n",
        "                  j.append(name)\n",
        "                  if 'ReLU' in str(type(module)):\n",
        "                      module.register_forward_hook(counting_forward_hook)\n",
        "                      module.register_backward_hook(counting_backward_hook)\n",
        "\n",
        "          #print('NUM MODULES IN ARCHITECTURES', len(j))\n",
        "          # Starting score algorithm\n",
        "          \n",
        "          network = network.to(device)\n",
        "          ## start time\n",
        "          #start = time.time()\n",
        "          #random.seed(config['seed'])\n",
        "          #np.random.seed(config['seed'])\n",
        "          #torch.manual_seed(config['seed'])\n",
        "          s = []\n",
        "          for j in range(config['maxofn']):\n",
        "              data_iterator = iter(train_dt)\n",
        "              x, target = next(data_iterator)\n",
        "              x2 = torch.clone(x)\n",
        "              x2 = x2.to(device)\n",
        "              x, target = x.to(device), target.to(device)\n",
        "              jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "              if 'hook_' in config['score']:\n",
        "                  network(x2.to(device))\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "              else:\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "          acc = acc_df['valid-accuracy'].iloc[uid]\n",
        "          print(f'Score (uid {uid}): {np.mean(s)}, Accuracy: {acc}')\n",
        "          stop = time.time()\n",
        "          result['uid'].append(uid)\n",
        "          result['score'].append(np.mean(s))\n",
        "          score = np.mean(s)\n",
        "          result['elapsed_time'].append(stop-start)\n",
        "\n",
        "          if config['point'] == '2a':\n",
        "          #point 2a\n",
        "            if score > best_score:\n",
        "              best_score = score\n",
        "              best_net = uid\n",
        "              best_acc = acc\n",
        "          else:\n",
        "            #point 2b\n",
        "            \n",
        "            if acc > best_acc:\n",
        "              best_acc = acc\n",
        "              best_score = score\n",
        "              best_net = uid\n",
        "\n",
        "          #print(f'Elapsed time (uid {uid}): {stop-start}')\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    df = pd.DataFrame.from_dict(result)\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    df.to_csv(f'./result_run{run_id}_trial{trial}_{point}_{dataset}.csv')\n",
        "    print(f'Best Network: {best_net}; Score: {best_score}; Accuracy: {best_acc}')\n",
        "    best = {}\n",
        "    best['acc'] = best_acc\n",
        "    best['score'] = best_score\n",
        "    best['uid'] = best_net\n",
        "    series_net = pd.Series(best)\n",
        "    series_net.to_csv(f'best_network_{run_id}_trial{trial}_{dataset}.csv')\n",
        "    return "
      ],
      "metadata": {
        "id": "4w8L81_mnF_H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#All Search"
      ],
      "metadata": {
        "id": "fyQKB2AfZmgc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "coGyuvqXUCLf"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "from neural_model.neural_model import get_cell_net\n",
        "from tqdm.notebook import tqdm\n",
        "from tqdm.contrib.telegram import tqdm, trange\n",
        "\n",
        "def search_all(run_id, dataset_id, device, start_uid, stop_uid):\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    #l = random.sample(range(max_uid), 100)\n",
        "    #for uid in tqdm(range(start_uid, stop_uid)):\n",
        "    for uid in tqdm(range(start_uid, stop_uid),\\\n",
        "       token='5374697833:AAFXE6wumxuSFFwpSzSmEQ6WL4jl8OBVOqw',\\\n",
        "       chat_id='142397010',\\\n",
        "       desc=f'result_run{run_id}_{start_uid//1000}_dataset{dataset_id}_'):\n",
        "      i = uid-start_uid\n",
        "      net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "      net_config: dict = get_standard_config(net_config)\n",
        "      network = get_cell_net(net_config)\n",
        "      try:\n",
        "          start = time.time()\n",
        "          if 'hook_' in config['score']:\n",
        "\n",
        "              def counting_forward_hook(module_hook, inp, out):\n",
        "                  try:\n",
        "                      if hasattr(module_hook, 'visited_backwards') and not module_hook.visited_backwards:\n",
        "                          return\n",
        "                      if isinstance(inp, tuple):\n",
        "                          inp = inp[0]\n",
        "                      inp = inp.view(inp.size(0), -1)\n",
        "                      x = (inp > 0).float()\n",
        "                      K = x @ x.t()\n",
        "                      K2 = (1. - x) @ (1. - x.t())\n",
        "                      if hasattr(network, 'K'):\n",
        "                        network.K = network.K + K.cpu().numpy() + K2.cpu().numpy()\n",
        "                      else: \n",
        "                        network.K = K.cpu().numpy() + K2.cpu().numpy()\n",
        "                  except Exception as exception:\n",
        "                      print(exception)\n",
        "                      pass\n",
        "\n",
        "\n",
        "              def counting_backward_hook(module_hook, inp, out):\n",
        "                  module_hook.visited_backwards = True\n",
        "\n",
        "              j = []\n",
        "              for name, module in network.named_modules():\n",
        "                  j.append(name)\n",
        "                  if 'ReLU' in str(type(module)):\n",
        "                      module.register_forward_hook(counting_forward_hook)\n",
        "                      module.register_backward_hook(counting_backward_hook)\n",
        "\n",
        "          #print('NUM MODULES IN ARCHITECTURES', len(j))\n",
        "          # Starting score algorithm\n",
        "          network = network.to(device)\n",
        "          ## start time\n",
        "          #start = time.time()\n",
        "          random.seed(config['seed'])\n",
        "          np.random.seed(config['seed'])\n",
        "          torch.manual_seed(config['seed'])\n",
        "          s = []\n",
        "          for j in range(config['maxofn']):\n",
        "              data_iterator = iter(train_dt)\n",
        "              x, target = next(data_iterator)\n",
        "              x2 = torch.clone(x)\n",
        "              x2 = x2.to(device)\n",
        "              x, target = x.to(device), target.to(device)\n",
        "              jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "              if 'hook_' in config['score']:\n",
        "                  network(x2.to(device))\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "              else:\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "          #print(f'Score (uid {uid}): {np.mean(s)}')\n",
        "          stop = time.time()\n",
        "          result['uid'].append(uid)\n",
        "          result['score'].append(np.mean(s))\n",
        "          result['elapsed_time'].append(stop-start)\n",
        "          #print(f'Elapsed time (uid {uid}): {stop-start}')\n",
        "          if i + 1 % 1000 == 0:\n",
        "            df = pd.DataFrame.from_dict(result)\n",
        "            result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "            df.to_csv(f'./NASWOT_result_run{run_id}_dataset{dataset_id}_{i}_.csv')\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    df = pd.DataFrame.from_dict(result)\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    df.to_csv(f'./result_run{run_id}_{start_uid//1000}_dataset{dataset_id}_LastRecords_.csv')\n",
        "    \n",
        "    return "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiuTUsbqU_LA"
      },
      "source": [
        "#Run Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def saving_results(trial):\n",
        "  path = f'./result_run{run_id}_trial{trial}_{point}_{dataset}.csv'\n",
        "  path_net = f'best_network_{run_id}_trial{trial}_{dataset}.csv'\n",
        "  \n",
        "  if point == '2a':\n",
        "    !cp -r $path_net /content/drive/MyDrive/project/2a/best\n",
        "    !cp -r $path /content/drive/MyDrive/project/2a/result\n",
        "    !rm $path\n",
        "    !rm $path_net\n",
        "  elif point == '2b':\n",
        "    !cp -r $path_net /content/drive/MyDrive/project/2b/best\n",
        "    !cp -r $path /content/drive/MyDrive/project/2b/result\n",
        "    !rm $path\n",
        "    !rm $path_net\n",
        "  # send_requests(trial)\n",
        "  return\n",
        "\n",
        "\n",
        "def send_requests(trial):\n",
        "  TOKEN = '5374697833:AAFXE6wumxuSFFwpSzSmEQ6WL4jl8OBVOqw'\n",
        "  CHAT_ID = '142397010'\n",
        "  SEND_URL = f'https://api.telegram.org/bot{TOKEN}/sendMessage'\n",
        "  your_message = f\"RUN COMPLETED!\\nInformation:\\n\\t\\t\\t\\t\\t\\t\\t\\tRun_Id:\\t{run_id}\\n\\t\\t\\t\\t\\t\\t\\t\\tTrial:{trial}\\n\\t\\t\\t\\t\\t\\t\\t\\tDataset_Id:\\t{dataset_id}\"\n",
        "  requests.post(SEND_URL, json={'chat_id': CHAT_ID, 'text': your_message}) \n",
        "  return"
      ],
      "metadata": {
        "id": "8CAsOTpzXDGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIh6uy9bUCI4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import requests\n",
        "import random\n",
        "import os\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.environ['WANDB_CONSOLE'] = 'off'\n",
        "start = time.time()\n",
        "\n",
        "run_id = config['run_id']\n",
        "dataset = config['dataset']\n",
        "start_uid = config['start_uid']\n",
        "stop_uid = config['stop_uid']\n",
        "n = config['n_random']    # N size of random sample\n",
        "trial = config['trial']\n",
        "\n",
        "rand_range = random.sample(range(1000), trial)\n",
        "print(rand_range)\n",
        "trial = 0\n",
        "#search_all(run_id, dataset_id, device, start_uid, stop_uid)\n",
        "for i in rand_range:\n",
        "  trial += 1\n",
        "  config['seed'] = i\n",
        "  naswot_search_n(run_id, dataset, device, n, trial)\n",
        "  saving_results(trial)\n",
        "\n",
        "\n",
        "stop = time.time()\n",
        "\n",
        "total_time = stop - start\n",
        "\n",
        "print(f'Total time for search over all searchspace: {total_time}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdWImgk0VCKr"
      },
      "source": [
        "#Save Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJd_rt9sUCGb"
      },
      "outputs": [],
      "source": [
        "#path = f'./result_run{run_id}_{start_uid//1000}_dataset{dataset_id}_LastRecords_.csv'\n",
        "path = f'./result_run{run_id}_{trial}_{dataset_id}.csv'\n",
        "path_net = f'best_network_{run_id}_trial{trial}_{dataset_id}.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cX8kz0hUCDm"
      },
      "outputs": [],
      "source": [
        "!cp -r $path /content/drive/MyDrive/project\n",
        "!cp -r $path_net /content/drive/MyDrive/project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-3jXt0ghbqj"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# import requests\n",
        "\n",
        "# TOKEN = '5374697833:AAFXE6wumxuSFFwpSzSmEQ6WL4jl8OBVOqw'\n",
        "# CHAT_ID = '142397010'\n",
        "# SEND_URL = f'https://api.telegram.org/bot{TOKEN}/sendMessage'\n",
        "# your_message = f\"RUN COMPLETED!\\nInformation:\\n\\t\\t\\t\\t\\t\\t\\t\\tRun_Id:\\t{run_id}\\n\\t\\t\\t\\t\\t\\t\\t\\tTrial:{trial}\\n\\t\\t\\t\\t\\t\\t\\t\\tDataset_Id:\\t{dataset_id}\"\n",
        "# requests.post(SEND_URL, json={'chat_id': CHAT_ID, 'text': your_message}) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aging Evolution Algorithm ðŸ¥‡\n",
        "\n",
        "### Algorithm Steps\n",
        "\n",
        "\n",
        "1.   Get N Random Architectures Called Population\n",
        "2.   Run Scoring Algorithm On Population\n",
        "3.   Take N Survivor, Choose As The Best Score\n",
        "4.   Create New Generation With Architecture At N Distance From The Survivor\n",
        "5.   Repeat From 2 For N Evolution Era\n",
        "\n"
      ],
      "metadata": {
        "id": "45pD-uhihnVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "from neural_model.neural_model import get_cell_net\n",
        "\n",
        "\"\"\"\n",
        "Find all architectures with a distance n (max), the distance is calculated as Hamming Distance\n",
        "\"\"\"\n",
        "\n",
        "def get_distance(arch_1, arch_2):\n",
        "  \"\"\"\n",
        "  Given two architectures calculate the distance between them in term of different operations or links\n",
        "  TO IMPLEMENT\n",
        "  \"\"\"\n",
        "  return random.randrange(15)\n",
        "\n",
        "def find_arch_n_dist(survivors, max_dist, anchestors):\n",
        "  population = []\n",
        "  for uid in survivors['uid']:\n",
        "    net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "    net_config: dict = get_standard_config(net_config)\n",
        "    for id in random.sample(range(0, max_uid), 1000):\n",
        "      candidate: pd.DataFrame = searchspace.loc[searchspace['uid'] == id]\n",
        "      candidate: dict = get_standard_config(candidate)\n",
        "      if id not in anchestors and get_distance(net_config, candidate) <= max_dist:\n",
        "        anchestors.append(id)\n",
        "        population.append(id)\n",
        "\n",
        "  return population\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYKfushphyQu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "from neural_model.neural_model import get_cell_net\n",
        "\n",
        "\"\"\"\n",
        "NAS WOT Algorithm\n",
        "\"\"\"\n",
        "\n",
        "def naswot_search(dataset, device, population) -> pd.DataFrame:\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': [], 'accuracy': []}\n",
        "    for uid in population:\n",
        "      net_config: pd.DataFrame = searchspace.loc[searchspace['uid'] == uid]\n",
        "      net_config: dict = get_standard_config(net_config)\n",
        "      network = get_cell_net(net_config)\n",
        "      try:\n",
        "          start = time.time()\n",
        "          if 'hook_' in config['score']:\n",
        "\n",
        "              def counting_forward_hook(module_hook, inp, out):\n",
        "                  try:\n",
        "                      if hasattr(module_hook, 'visited_backwards') and not module_hook.visited_backwards:\n",
        "                          return\n",
        "                      if isinstance(inp, tuple):\n",
        "                          inp = inp[0]\n",
        "                      inp = inp.view(inp.size(0), -1)\n",
        "                      x = (inp > 0).float()\n",
        "                      K = x @ x.t()\n",
        "                      K2 = (1. - x) @ (1. - x.t())\n",
        "                      if hasattr(network, 'K'):\n",
        "                        network.K = network.K + K.cpu().numpy() + K2.cpu().numpy()\n",
        "                      else: \n",
        "                        network.K = K.cpu().numpy() + K2.cpu().numpy()\n",
        "                  except Exception as exception:\n",
        "                      print(exception)\n",
        "                      pass\n",
        "\n",
        "\n",
        "              def counting_backward_hook(module_hook, inp, out):\n",
        "                  module_hook.visited_backwards = True\n",
        "\n",
        "              j = []\n",
        "              for name, module in network.named_modules():\n",
        "                  j.append(name)\n",
        "                  if 'ReLU' in str(type(module)):\n",
        "                      module.register_forward_hook(counting_forward_hook)\n",
        "                      module.register_backward_hook(counting_backward_hook)\n",
        "          network = network.to(device)\n",
        "          s = []\n",
        "          for j in range(config['maxofn']):\n",
        "              data_iterator = iter(train_dt)\n",
        "              x, target = next(data_iterator)\n",
        "              x2 = torch.clone(x)\n",
        "              x2 = x2.to(device)\n",
        "              x, target = x.to(device), target.to(device)\n",
        "              jacobs, labels, y, out = get_batch_jacobian(network, x, target, device, config)\n",
        "              if 'hook_' in config['score']:\n",
        "                  network(x2.to(device))\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "              else:\n",
        "                  value = hooklogdet(network.K, target)\n",
        "                  s.append(value)\n",
        "          acc = acc_df['valid-accuracy'].iloc[uid]\n",
        "          print(f'Score (uid {uid}): {np.mean(s)}, Accuracy: {acc}')\n",
        "          stop = time.time()\n",
        "          result['uid'].append(uid)\n",
        "          result['score'].append(np.mean(s))\n",
        "          result['accuracy'].append(acc)\n",
        "          score = np.mean(s)\n",
        "          result['elapsed_time'].append(stop-start)\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "    df = pd.DataFrame.from_dict(result)\n",
        "    result = {'uid': [], 'score': [], 'elapsed_time': []}\n",
        "    return df"
      ],
      "metadata": {
        "id": "G18K3jznCcdL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get N Random Samples\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = config['dataset']\n",
        "population = random.sample(range(max_uid), config['n_random'])\n",
        "survivors = {}\n",
        "anchestors = population.copy()\n",
        "# Run Algorithm on Population\n",
        "\n",
        "for i in range(config['n_evolution']):\n",
        "  trained_population = naswot_search(dataset, device, population)\n",
        "  print('TRAINED', trained_population)\n",
        "  # Take N Survivor\n",
        "  trained_population.sort_values(by=['score'], ascending=False, inplace=True)\n",
        "  survivors = trained_population.head(config['n_survivor'])\n",
        "  print('SURVIVORS', survivors)\n",
        "\n",
        "  # Create New Generation\n",
        "  population = find_arch_n_dist(survivors=survivors.to_dict(), max_dist=config['n_arch_distance'], anchestors=anchestors)\n",
        "  \n",
        "  print(len(population), population)\n",
        "  print('ANCHESTORS')\n",
        "  print(anchestors)\n",
        "survivors\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YxMZA3Damyvk",
        "outputId": "ff6a54ea-539f-4670-8100-07383848f54f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score (uid 2522): 1585.8323974609375, Accuracy: 70.69199999511719\n",
            "Score (uid 10595): 1631.5406494140625, Accuracy: 79.94799999511719\n",
            "Score (uid 13943): 1446.0458984375, Accuracy: 56.639999998779295\n",
            "Score (uid 8253): 1669.1312255859375, Accuracy: 83.97599997314452\n",
            "Score (uid 5509): 1643.5167236328125, Accuracy: 70.83599997314452\n",
            "Score (uid 12413): 1671.2928466796875, Accuracy: 79.86799998535156\n",
            "Score (uid 2133): 1508.6676025390625, Accuracy: 61.06799998657227\n",
            "Score (uid 6351): 1640.9896240234375, Accuracy: 72.22799997070312\n",
            "Score (uid 2581): 1702.501953125, Accuracy: 84.9680000024414\n",
            "Score (uid 8115): 1513.7320556640625, Accuracy: 82.01599998779297\n",
            "TRAINED      uid        score  elapsed_time  accuracy\n",
            "0   2522  1585.832397      1.123986    70.692\n",
            "1  10595  1631.540649      1.251739    79.948\n",
            "2  13943  1446.045898      1.041358    56.640\n",
            "3   8253  1669.131226      1.341515    83.976\n",
            "4   5509  1643.516724      1.244630    70.836\n",
            "5  12413  1671.292847      1.346447    79.868\n",
            "6   2133  1508.667603      1.211908    61.068\n",
            "7   6351  1640.989624      1.254556    72.228\n",
            "8   2581  1702.501953      1.713528    84.968\n",
            "9   8115  1513.732056      1.252366    82.016\n",
            "SURVIVORS      uid        score  elapsed_time  accuracy\n",
            "8   2581  1702.501953      1.713528    84.968\n",
            "5  12413  1671.292847      1.346447    79.868\n",
            "3   8253  1669.131226      1.341515    83.976\n",
            "4   5509  1643.516724      1.244630    70.836\n",
            "7   6351  1640.989624      1.254556    72.228\n",
            "20 [4603, 15276, 2220, 4052, 2106, 11443, 7550, 5547, 10278, 7030, 2448, 11338, 1053, 1367, 15495, 5083, 2351, 14360, 447, 9422]\n",
            "ANCHESTORS\n",
            "[2522, 10595, 13943, 8253, 5509, 12413, 2133, 6351, 2581, 8115, 4603, 15276, 2220, 4052, 2106, 11443, 7550, 5547, 10278, 7030, 2448, 11338, 1053, 1367, 15495, 5083, 2351, 14360, 447, 9422, 15185, 13334, 1449, 8014, 8631, 1805, 9418, 12992, 15534, 3331, 14098, 1736, 12401, 6612, 5713, 12729, 10970, 4956, 11035, 6472, 3088, 8584, 12622, 9715, 10303, 8671, 3661, 6587, 8687, 8251, 7846, 8705, 1472, 8794, 13162, 1487, 2457, 14599, 679, 15476, 10873, 9898, 2021, 1462, 500, 10555, 10152, 5598, 10336, 2700, 4, 1237, 11799, 3503, 12241, 5851, 1913, 6093, 2376, 13419, 4467, 8547, 4115, 14217, 12628, 8508, 581, 7892, 7975, 15558, 457, 7458, 7755, 5761, 4268, 9773, 303, 11949, 6724, 13622, 15025, 3604, 8608, 13415, 5873, 13813, 2415, 9724, 7948, 13525, 3185, 9245, 14622, 1323, 12816, 6500, 1891, 10319, 7039, 9508, 5277, 7666, 11618, 1339, 9783, 7241, 15485, 7563, 1569, 8990, 12186, 3891, 14514, 10764, 6506, 10978, 7842, 13538, 5823, 7918, 1544, 3953, 7504, 13089, 8074, 959, 11504, 6210, 4962, 980, 4744, 11124, 13296, 10089, 2681, 2016, 227, 7001, 15129, 11730, 13249, 9679, 3164, 9019, 5982, 10225, 5306, 13728, 5954, 9890, 15136, 3875, 8610, 13145, 4616, 5080, 11421, 7404, 1479, 8829, 2806, 2694, 377, 4146, 11729, 6344, 11571, 1850, 4892, 13121, 2085, 9116, 9993, 7473, 15317, 5433, 3204, 13067, 11606, 2972, 2049, 790, 11608, 9980, 9266, 8499, 14602, 223, 6230, 11200, 8362, 4618, 14789, 6978, 13658, 10501, 11828, 8953, 864, 8888, 13812, 6668, 5331, 10108, 14261, 3979, 9570, 4791, 2012, 14454, 6533, 13358, 13556, 839, 10013, 3550, 8202, 10983, 3804, 412, 972, 4562, 15514, 9111, 3023, 4576, 7821, 12346, 14470, 3918, 3470, 13187, 15290, 7501, 13640, 7137, 11060, 10971, 10890, 12496, 4610, 9730, 4181, 11676, 6281, 6068, 2385, 14213, 11345, 13345, 11210, 10324, 11247, 14628, 4647, 6504, 8247, 8357, 5172, 4252, 2869, 14403, 10888, 11373, 11411, 5064, 12352, 87, 12652, 7695, 3850, 9177, 12180, 8579, 7941, 9518, 4229, 6268, 4002, 7242, 811, 5254, 11662, 11399, 858, 13806, 12310, 14879, 14825, 13732, 14040, 12044, 395, 5242, 3995, 2545, 10830, 13570, 8590, 1727, 7146, 6571, 6190, 805, 4716, 5562, 7594, 11815, 9406, 10739, 5898, 1926, 6239, 8093, 7864, 2851, 8359, 232, 4295, 2033, 13587, 7876, 5367, 6758, 5538, 8995, 781, 4357, 10935, 5431, 6809, 3474, 2184, 13563, 11336, 14692, 2874, 3354, 8, 5520, 8949, 7897, 5997, 5785, 4590, 4645, 13850, 8595, 8897, 3705, 5702, 5449, 8947, 10540, 8121, 12357, 5244, 14019, 13468, 11238, 7548, 13623, 7651, 525, 5517, 9136, 1711, 2241, 14912, 9552, 11454, 1624, 4846, 1341, 8567, 11892, 8778, 8007, 9973, 4841, 14234, 2400, 3756, 9281, 2962, 14743, 9373, 14604, 14846, 9335, 13458, 9625, 2436, 14802, 4289, 11834, 13929, 3694, 11425, 15047, 11720, 10131, 365, 1493, 3201, 10323, 9640, 8658, 12737, 1223, 3396, 8886, 15440, 8765, 14944, 11667, 3278, 9698, 6120, 11245, 8737, 9112, 12376, 4717, 11858, 13816, 4156, 9768, 5181, 6884, 9856, 3394, 1734, 7177, 4008, 8908, 10895, 14849, 15212, 6653, 13978, 9697, 10726, 14456, 3907, 11544, 9231, 9851, 13440, 5902, 14159, 6823, 9672, 4891, 11471, 12495, 5787, 14167, 2554, 1271, 9673, 5245, 7796, 9848, 5018, 5543, 4864, 11624, 12533, 1314, 6448, 6161, 4500, 6054, 14941, 5143, 7015, 7573, 9352, 1778, 10541, 4718, 1116, 7628, 2556, 11161, 10659, 12614, 14233, 715, 7731, 3990, 14001, 11914, 8483, 8035, 6249, 15250, 13072, 15087, 3052, 15043, 5278, 13781, 1810, 2432, 4863, 7000, 12582, 4938, 13421, 12935, 8868, 4465, 6592, 9368, 6763, 8498, 5142, 5815, 15234, 2258, 8165, 6638, 1274, 3424, 6466, 7636, 514, 3646, 755, 13508, 5456, 826, 3737, 7529, 13259, 10742, 4416, 13504, 6392, 4015, 14192, 11006, 9387, 11351, 14610, 9844, 4720, 4237, 8393, 13034, 13552, 11303, 3973, 7880, 8831, 9366, 15355, 349, 13080, 375, 9355, 15415, 1424, 6543, 385, 3873, 4305, 12621, 11007, 13131, 4777, 2980, 13547, 4667, 11980, 14452, 2470, 12750, 13140, 11619, 5259, 10964, 11645, 2389, 8122, 515, 11412, 994, 12015, 5885, 6954, 3631, 11174, 13141, 3586, 1699, 11853, 4436, 12800, 265, 15139, 11909, 4498, 3643, 5585, 1167, 8197, 3676, 2524, 7345, 11903, 818, 6133, 2340, 13558, 9968, 9674, 3432, 9725, 13811, 5201, 14002, 15545, 9028, 11467, 4374, 5722, 11356, 5909, 2809, 12612, 2235, 6236, 7887, 4205, 8744, 8449, 14375, 2552, 10111, 7578, 5461, 14232, 6688, 3659, 4269, 950, 461, 12959, 3529, 11912, 7970, 9656, 798, 14401, 3549, 371, 2785, 2675, 15324, 14606, 12698, 14954, 7682, 995, 7266, 4489, 10838, 10854, 6018, 5443, 8286, 8261, 4961, 345, 5923, 9510, 7364, 2320, 4522, 2433, 3592, 5316, 10222, 6877, 4762, 469, 13941, 5046, 7312, 5981, 7859, 10620, 1489, 8948, 4310, 1749, 1969, 5546, 6697, 2897, 4152, 9575, 9902, 1072, 1145, 9209, 11054, 788, 9223, 13951, 5637, 7159, 673, 15559, 9056, 10914, 5676, 6426, 10781, 11300, 9880, 1134, 15596, 7622, 14479, 2630, 7513, 6299, 10505, 7119, 7091, 11703, 13852, 12234, 1103, 414, 12076, 920, 11286, 12329, 3527, 1675, 10771, 8676, 9512, 4707, 3788, 7938, 3899, 12883, 10368, 4210, 10606, 2474, 14600, 4911, 8959, 10818, 6947, 14269, 13219, 7283, 7008, 12783, 2309, 14601, 9454, 11611, 10348, 10047, 11825, 8198, 14664, 3699, 4974, 10051, 10244, 6097, 14571, 7314, 13253, 12742, 4928, 13144, 6723, 12920, 14752, 9257, 443, 10135, 181, 1426, 4165, 11428, 2195, 14484, 8175, 2632, 5846, 7817, 9138, 15508, 14726, 7230, 2073, 15546, 13442, 14347, 11895, 6169, 12778, 11225, 5389, 13311, 5477, 1752, 2621, 3405, 2216, 9876, 6744, 12886, 14453, 697, 2310, 1602, 247, 6522, 9626, 13697, 2194, 12655, 3837, 7610, 4284, 5652, 3440, 13046, 14090, 4417, 11246, 8634, 2684, 8429, 11639, 10150, 3986, 14544, 4931, 14831, 731, 13526, 14371, 171, 9949, 2690, 5861, 10456, 4470, 43, 10338, 3450, 1920, 8666, 7528, 3119, 11386, 5586, 5629, 4292, 12139, 6654, 13901, 2046, 3867, 10182, 81, 5204, 6251, 14189, 9292, 1937, 14321, 5363, 4452, 3720, 3422, 3715, 9828, 5479, 13918, 13626, 5972, 9164, 6875, 9520, 15090, 1716, 4900, 15082, 9344, 10281, 7057, 1272, 9728, 9559, 6631, 4700, 10522, 8418, 6203, 4085, 9873, 4124, 2584, 209, 15413, 2875, 11805, 5964, 8087, 5853, 3510, 2891, 3974, 12122, 14916, 8731, 9412, 6145, 3181, 13019, 1564, 142, 6950, 14904, 6925, 6646, 15385, 7298, 13258, 1332, 10639, 13836, 8849, 4512, 1231, 11489, 10590, 8284, 13159, 757, 13065, 7069, 2485, 7399, 14069, 12961, 13532, 8142, 3910, 12884, 2582, 2001, 8894, 15096, 3232, 12098, 12474, 1225, 13432, 1508, 5647, 12433, 14076, 14572, 12359, 14986, 2929, 4028, 7463, 4753, 2703, 14869, 2738, 15542, 2019, 10370, 7574, 2141, 9345, 3223, 2427, 3176, 1687, 8382, 5631, 12182, 5079, 9786, 570, 2409, 482, 3923, 10272, 1039, 607, 12227, 5551, 4437, 4402, 7767, 15150, 4671, 11765, 9222, 14828, 5139, 856, 3441, 11616, 8456, 9010, 691, 15360, 237, 9514, 1331, 12983, 1064, 4011, 2406, 13254, 7724, 1374, 1750, 966, 9390, 8015, 16, 8244, 4764, 4656, 1956, 2689, 12289, 4526, 4738, 7613, 11875, 2144, 12892, 11032, 11760, 929, 12818, 13715, 11860, 11090, 4262, 2513, 15582, 15417, 471, 15046, 5695, 11727, 10761, 6496, 5270, 5992, 5034, 1947, 6705, 5192, 10034, 1534, 4447, 13302, 4507, 14680, 8423, 10615, 4693, 4372, 8442, 1434, 2721, 7945, 2863, 14195, 1813, 12850, 2761, 604, 2961, 6685, 1672, 5922, 11758, 6219, 1190, 7368, 7109, 57, 12664, 9781, 7568, 3842, 5094, 12613, 11227, 1363, 5687, 2095, 7712, 14924, 912, 458, 8615, 9498, 3507, 1120, 14542, 9081, 11362, 2174, 10313, 10795, 9647, 14903, 3238, 7452, 11656, 8578, 3540, 13276, 666, 9308, 2214, 10385, 9882, 8830, 10792, 7111, 9095, 5442, 4009, 7627, 2276, 9388, 15548, 6567, 4107, 7700, 13571, 669, 10187, 4021, 8534, 8540, 6881, 10079, 11910, 6375, 7889, 9833, 8768, 14405, 2104, 3588, 4992, 5241, 3999, 6193, 8635, 7097, 4854, 2979, 11306, 8103, 6873, 1004, 12058, 4702, 4605, 1182, 10616, 8669, 7933, 12560, 1459, 11779, 3303, 11170, 10882, 5176, 4655, 5490, 390, 3353, 2953, 2867, 2983, 12382, 2367, 12635, 7845, 13074, 6694, 7591, 2287, 12584, 6143, 15588, 12697, 12832, 11833, 8388, 10833, 5493, 4747, 2253, 11212, 852, 11806, 12607, 4347, 7969, 5310, 13498, 1870, 6109, 4112, 13168, 4612, 12542, 4770, 11316, 5569, 5342, 1817, 8226, 8256, 41, 6451, 4272, 12815, 942, 10667, 9925, 4932, 8683, 13111, 4349, 8058, 13294, 8926, 6123, 9337, 6287, 8370, 12312, 7375, 7503, 1683, 7223, 1203, 1207, 9386, 6931, 9416, 9727, 226, 12249, 3858, 953, 11499, 5500, 4345, 15594, 14580, 14448, 5582, 7078, 6255, 1657, 14070, 10365, 10068, 14216, 5178, 427, 4999, 13709, 12725, 7730, 13138, 14559, 9350, 12228, 2370, 1312, 6117, 4401, 6714, 999, 13412, 13181, 11890, 945, 2543, 6164, 3089, 4805, 5824, 9562, 14660, 11804, 9975, 764, 692, 12926, 12129, 2227, 4227, 10734, 15302, 13657, 11234, 5348, 10015, 8841, 6942, 2352, 1763, 7049, 13248, 4674, 10518, 4190, 1483, 8207, 4369, 1247, 9952, 3200, 13205, 91, 9489, 14036, 6912, 14589, 4499, 15289, 7331, 307, 9603, 4838, 13189, 3234, 1520, 330, 7630, 14287, 9098, 11808, 4097, 120, 4068, 2131, 3967, 5256, 4445, 11812, 8307, 12647, 4767, 728, 14179, 955, 11282, 10626, 188, 582, 10190, 1117, 2625, 4880, 168, 12876, 5136, 6378, 2428, 13763, 6649, 3241, 12266, 2257, 9465, 9034, 6733, 356, 2102, 12432, 7909, 5680, 14552, 12561, 2544, 8811, 1858, 5144, 7659, 9567, 186, 857, 8430, 2362, 5087, 455, 14840, 9060, 11723, 1503, 2995, 9020, 12781, 7919, 14245, 9166, 11922, 10503, 6011, 3019, 13593, 3082, 14749, 3352, 12390, 10738, 13215, 2259, 311, 587, 10784, 6814, 9638, 6146, 4147, 2336, 5542, 639, 2536, 7354, 1333, 14107, 7291, 4224, 2044, 5825, 9620, 4059, 3345, 11079, 10494, 13520, 3012, 3793, 15377, 12954, 3648, 6078, 15028, 11315, 7961, 8016, 13245, 14631, 9449, 5659, 14900, 2283, 6558, 2430, 9670, 6840, 15024, 13613, 12768, 6620, 6004, 7113, 12041, 15494, 7259, 1321, 7281, 4662, 14499, 9938, 10737, 842, 4593, 8746, 164, 8855, 3309, 13271, 1448, 12094, 15017, 15393, 2782, 5619, 6406, 14390, 14723, 7067, 6350, 5618, 8454, 4564, 10731, 5073, 5305, 1781, 10411, 5648, 8971, 10061, 9870, 8486, 7752, 10744, 13588, 3767, 7083, 1764, 7446, 12719, 5347, 973, 3136, 7917, 2140, 5733, 12780, 13295, 10460, 675, 5298, 9363, 14066, 3833, 13030, 6267, 3227, 8844, 2925, 4036, 5311, 9667, 11015, 13275, 8925, 1964, 8237, 13896, 449, 14746, 313, 10670, 2333, 2455, 13880, 6833, 8861, 14918, 11961, 13201, 907, 4886, 13282, 1249, 5066, 12871, 15203, 9185, 8219, 14015, 9944, 1277, 102, 10035, 7263, 4875, 10495, 10166, 9589, 10879, 10953, 14348, 7547, 4333, 10358, 12165, 11944, 13357, 601, 12319, 15427, 3273, 7597, 7951, 12300, 3224, 13686, 7763, 8848, 3461, 10428, 462, 10383, 8306, 1560, 4278, 1653, 2078, 15390, 10025, 4768, 3917, 13395, 8910, 13924, 3878, 9843, 6698, 14496, 11700, 234, 7998, 12929, 6180, 6026, 12788, 297, 3117, 1465, 9398, 9859, 14665, 11581, 10755, 2994, 7429, 9550, 991, 11634, 825, 4862, 12491, 5196, 10334, 14038, 5636, 9962, 7807, 703, 11095, 6023, 14262, 11318, 6555, 7406, 9513, 13467, 7911, 9930, 1519, 8660, 6764, 15179, 2608, 7830, 11473, 1737, 439, 13321, 7643, 12003, 13703, 11753, 13186, 15327, 9517, 9054, 14104, 8646, 2413, 11562, 12899, 8814, 10117, 13939, 10775, 15241, 3567, 8528, 6798, 5839, 6077, 0, 11625, 7273, 11277, 3319, 10504, 11894, 12238, 7879, 12211, 14231, 12, 12297, 8887, 11004, 13708, 7415, 3288, 1340, 10654, 14864, 10783, 4595, 810, 3046, 10486, 12641, 14297, 4686, 5299, 15482, 7555, 9801, 2035, 13610, 5968, 11636, 11734, 10279, 14921, 4230, 15161, 11424, 12179, 5300, 14400, 1473, 15595, 5118, 10488, 1492, 4012, 2826, 8223, 14623, 11793, 1098, 4739, 19, 10402, 6307, 4555, 12187, 520, 12711, 12079, 11702, 4281, 12900, 8520, 4030, 8689, 10780, 6389, 1974, 5996, 6444, 7544, 12999, 13985, 3651, 6428, 2861, 3994, 4228, 1893, 8426, 11561, 13841, 15050, 9913, 161, 4668, 7381, 5238, 9919, 4213, 14325, 1466, 11093, 11501, 7348, 7790, 6715, 9790, 254, 7603, 4432, 14742, 12680, 516, 3755, 2398, 12802, 7391, 5282, 11455, 12373, 10822, 11135, 4915, 11982, 5752, 6610, 2042, 11679, 6101, 283, 10167, 8806, 8643, 12002, 5699, 5915, 6025, 14356, 11684, 8064, 12922, 3816, 2116, 12634, 15437, 2598, 2768, 10532, 4502, 4967, 3491, 4927, 14541, 14099, 1791, 12092, 2266, 14174, 10743, 2647, 4070, 2573, 14328, 10077, 9746, 3561, 10398, 7065, 15620, 8178, 304, 5429, 8094, 4745, 4428, 7313, 5050, 5938, 11596, 10173, 4497, 12485, 3892, 5973, 6155, 15457, 10003, 14450, 3611, 665, 14054, 944, 545, 1263, 12240, 15186, 1043, 2443, 14017, 14695, 8334, 2246, 6842, 15460, 3247, 6122, 3407, 1674, 9197, 1214, 734, 1912, 10032, 9804, 7558, 8876, 9862, 5314, 9471, 1936, 3594, 3092, 7344, 10483, 2739, 4666, 8224, 13885, 1437, 11674, 3301, 12924, 8963, 13206, 4119, 2933, 13338, 13380, 3943, 13913, 8343, 14096, 13352, 1163, 1171, 1999, 10308, 10806, 2117, 15435, 1628, 15019, 584, 14422, 13427, 8340, 11978, 14839, 5412, 10878, 4799, 5962, 4826, 2515, 11838, 13476, 8324, 7500, 9488, 10387, 8503, 8518, 12989, 12294, 14355, 9666, 15453, 14676, 10506, 11970, 10539, 7465, 9150, 6574, 2683, 11784, 12559, 8248, 1809, 11329, 5910, 9977, 7278, 12151, 12770, 10487, 8193, 4084, 9712, 3125, 6188, 9713, 10919, 2685, 4540, 3036, 8967, 14808, 3813, 4959, 5724, 1807, 15138, 14317, 6713, 10732, 569, 13636, 865, 13685, 14273, 4637, 9963, 14224, 6465, 12203, 8700, 8724, 8387, 4765, 11953, 15198, 554, 8010, 14784, 5025, 9483, 5753, 9251, 8546, 1836, 13480, 3806, 15269, 14423, 1206, 13212, 11272, 12660, 11363, 9198, 10259, 14242, 1966, 5324, 9191, 7284, 9152, 90, 12877, 1416, 2561, 11584, 4492, 3686, 5894, 6936, 7416, 7688, 12490, 1521, 733, 14799, 1925, 1685, 9396, 6648, 5338, 1690, 3166, 10001, 10593, 5820, 15422, 2902, 7271, 1667, 9850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score (uid 4603): 1302.2113037109375, Accuracy: 73.80000000488282\n",
            "Score (uid 15276): 1588.3629150390625, Accuracy: 70.42000001953124\n",
            "Score (uid 2220): 1502.67919921875, Accuracy: 51.66799999511719\n",
            "Score (uid 4052): 1626.87255859375, Accuracy: 75.62800000488281\n",
            "Score (uid 2106): 1631.7923583984375, Accuracy: 55.9\n",
            "Score (uid 11443): 1634.73876953125, Accuracy: 83.63200001220703\n",
            "Score (uid 7550): 1647.5179443359375, Accuracy: 79.05199999023438\n",
            "Score (uid 5547): 1511.8187255859375, Accuracy: 81.44399998535157\n",
            "Score (uid 10278): 1634.1209716796875, Accuracy: 74.56800000244141\n",
            "Score (uid 7030): 1638.0994873046875, Accuracy: 83.27999998779296\n",
            "Score (uid 2448): 1501.892578125, Accuracy: 72.1040000048828\n",
            "Score (uid 11338): 1589.04150390625, Accuracy: 78.78799998046875\n",
            "Score (uid 1053): 1673.2445068359375, Accuracy: 76.65199997314453\n",
            "Score (uid 1367): 1643.8980712890625, Accuracy: 80.1919999975586\n",
            "Score (uid 15495): 1681.8997802734375, Accuracy: 78.2240000024414\n",
            "Score (uid 5083): 1633.13037109375, Accuracy: 72.72399997558594\n",
            "Score (uid 2351): 1538.0142822265625, Accuracy: 64.78799997314454\n",
            "Score (uid 14360): 1566.5899658203125, Accuracy: 76.12399998291015\n",
            "Score (uid 447): 1493.8492431640625, Accuracy: 69.20399997070312\n",
            "Score (uid 9422): 1491.8270263671875, Accuracy: 66.12399998291015\n",
            "TRAINED       uid        score  elapsed_time  accuracy\n",
            "0    4603  1302.211304      0.863804    73.800\n",
            "1   15276  1588.362915      1.167773    70.420\n",
            "2    2220  1502.679199      1.020597    51.668\n",
            "3    4052  1626.872559      1.241133    75.628\n",
            "4    2106  1631.792358      1.284587    55.900\n",
            "5   11443  1634.738770      1.252679    83.632\n",
            "6    7550  1647.517944      1.290516    79.052\n",
            "7    5547  1511.818726      1.050250    81.444\n",
            "8   10278  1634.120972      1.271722    74.568\n",
            "9    7030  1638.099487      1.273251    83.280\n",
            "10   2448  1501.892578      1.099668    72.104\n",
            "11  11338  1589.041504      1.149049    78.788\n",
            "12   1053  1673.244507      1.396110    76.652\n",
            "13   1367  1643.898071      1.290066    80.192\n",
            "14  15495  1681.899780      1.347902    78.224\n",
            "15   5083  1633.130371      1.237977    72.724\n",
            "16   2351  1538.014282      1.148056    64.788\n",
            "17  14360  1566.589966      1.129403    76.124\n",
            "18    447  1493.849243      1.046957    69.204\n",
            "19   9422  1491.827026      1.036230    66.124\n",
            "SURVIVORS       uid        score  elapsed_time  accuracy\n",
            "14  15495  1681.899780      1.347902    78.224\n",
            "12   1053  1673.244507      1.396110    76.652\n",
            "6    7550  1647.517944      1.290516    79.052\n",
            "13   1367  1643.898071      1.290066    80.192\n",
            "9    7030  1638.099487      1.273251    83.280\n",
            "20 [5197, 15078, 12043, 6106, 7878, 7228, 12243, 13634, 11154, 5381, 10122, 11688, 5308, 15489, 4171, 6499, 10199, 15552, 13910, 13863]\n",
            "ANCHESTORS\n",
            "[2522, 10595, 13943, 8253, 5509, 12413, 2133, 6351, 2581, 8115, 4603, 15276, 2220, 4052, 2106, 11443, 7550, 5547, 10278, 7030, 2448, 11338, 1053, 1367, 15495, 5083, 2351, 14360, 447, 9422, 15185, 13334, 1449, 8014, 8631, 1805, 9418, 12992, 15534, 3331, 14098, 1736, 12401, 6612, 5713, 12729, 10970, 4956, 11035, 6472, 3088, 8584, 12622, 9715, 10303, 8671, 3661, 6587, 8687, 8251, 7846, 8705, 1472, 8794, 13162, 1487, 2457, 14599, 679, 15476, 10873, 9898, 2021, 1462, 500, 10555, 10152, 5598, 10336, 2700, 4, 1237, 11799, 3503, 12241, 5851, 1913, 6093, 2376, 13419, 4467, 8547, 4115, 14217, 12628, 8508, 581, 7892, 7975, 15558, 457, 7458, 7755, 5761, 4268, 9773, 303, 11949, 6724, 13622, 15025, 3604, 8608, 13415, 5873, 13813, 2415, 9724, 7948, 13525, 3185, 9245, 14622, 1323, 12816, 6500, 1891, 10319, 7039, 9508, 5277, 7666, 11618, 1339, 9783, 7241, 15485, 7563, 1569, 8990, 12186, 3891, 14514, 10764, 6506, 10978, 7842, 13538, 5823, 7918, 1544, 3953, 7504, 13089, 8074, 959, 11504, 6210, 4962, 980, 4744, 11124, 13296, 10089, 2681, 2016, 227, 7001, 15129, 11730, 13249, 9679, 3164, 9019, 5982, 10225, 5306, 13728, 5954, 9890, 15136, 3875, 8610, 13145, 4616, 5080, 11421, 7404, 1479, 8829, 2806, 2694, 377, 4146, 11729, 6344, 11571, 1850, 4892, 13121, 2085, 9116, 9993, 7473, 15317, 5433, 3204, 13067, 11606, 2972, 2049, 790, 11608, 9980, 9266, 8499, 14602, 223, 6230, 11200, 8362, 4618, 14789, 6978, 13658, 10501, 11828, 8953, 864, 8888, 13812, 6668, 5331, 10108, 14261, 3979, 9570, 4791, 2012, 14454, 6533, 13358, 13556, 839, 10013, 3550, 8202, 10983, 3804, 412, 972, 4562, 15514, 9111, 3023, 4576, 7821, 12346, 14470, 3918, 3470, 13187, 15290, 7501, 13640, 7137, 11060, 10971, 10890, 12496, 4610, 9730, 4181, 11676, 6281, 6068, 2385, 14213, 11345, 13345, 11210, 10324, 11247, 14628, 4647, 6504, 8247, 8357, 5172, 4252, 2869, 14403, 10888, 11373, 11411, 5064, 12352, 87, 12652, 7695, 3850, 9177, 12180, 8579, 7941, 9518, 4229, 6268, 4002, 7242, 811, 5254, 11662, 11399, 858, 13806, 12310, 14879, 14825, 13732, 14040, 12044, 395, 5242, 3995, 2545, 10830, 13570, 8590, 1727, 7146, 6571, 6190, 805, 4716, 5562, 7594, 11815, 9406, 10739, 5898, 1926, 6239, 8093, 7864, 2851, 8359, 232, 4295, 2033, 13587, 7876, 5367, 6758, 5538, 8995, 781, 4357, 10935, 5431, 6809, 3474, 2184, 13563, 11336, 14692, 2874, 3354, 8, 5520, 8949, 7897, 5997, 5785, 4590, 4645, 13850, 8595, 8897, 3705, 5702, 5449, 8947, 10540, 8121, 12357, 5244, 14019, 13468, 11238, 7548, 13623, 7651, 525, 5517, 9136, 1711, 2241, 14912, 9552, 11454, 1624, 4846, 1341, 8567, 11892, 8778, 8007, 9973, 4841, 14234, 2400, 3756, 9281, 2962, 14743, 9373, 14604, 14846, 9335, 13458, 9625, 2436, 14802, 4289, 11834, 13929, 3694, 11425, 15047, 11720, 10131, 365, 1493, 3201, 10323, 9640, 8658, 12737, 1223, 3396, 8886, 15440, 8765, 14944, 11667, 3278, 9698, 6120, 11245, 8737, 9112, 12376, 4717, 11858, 13816, 4156, 9768, 5181, 6884, 9856, 3394, 1734, 7177, 4008, 8908, 10895, 14849, 15212, 6653, 13978, 9697, 10726, 14456, 3907, 11544, 9231, 9851, 13440, 5902, 14159, 6823, 9672, 4891, 11471, 12495, 5787, 14167, 2554, 1271, 9673, 5245, 7796, 9848, 5018, 5543, 4864, 11624, 12533, 1314, 6448, 6161, 4500, 6054, 14941, 5143, 7015, 7573, 9352, 1778, 10541, 4718, 1116, 7628, 2556, 11161, 10659, 12614, 14233, 715, 7731, 3990, 14001, 11914, 8483, 8035, 6249, 15250, 13072, 15087, 3052, 15043, 5278, 13781, 1810, 2432, 4863, 7000, 12582, 4938, 13421, 12935, 8868, 4465, 6592, 9368, 6763, 8498, 5142, 5815, 15234, 2258, 8165, 6638, 1274, 3424, 6466, 7636, 514, 3646, 755, 13508, 5456, 826, 3737, 7529, 13259, 10742, 4416, 13504, 6392, 4015, 14192, 11006, 9387, 11351, 14610, 9844, 4720, 4237, 8393, 13034, 13552, 11303, 3973, 7880, 8831, 9366, 15355, 349, 13080, 375, 9355, 15415, 1424, 6543, 385, 3873, 4305, 12621, 11007, 13131, 4777, 2980, 13547, 4667, 11980, 14452, 2470, 12750, 13140, 11619, 5259, 10964, 11645, 2389, 8122, 515, 11412, 994, 12015, 5885, 6954, 3631, 11174, 13141, 3586, 1699, 11853, 4436, 12800, 265, 15139, 11909, 4498, 3643, 5585, 1167, 8197, 3676, 2524, 7345, 11903, 818, 6133, 2340, 13558, 9968, 9674, 3432, 9725, 13811, 5201, 14002, 15545, 9028, 11467, 4374, 5722, 11356, 5909, 2809, 12612, 2235, 6236, 7887, 4205, 8744, 8449, 14375, 2552, 10111, 7578, 5461, 14232, 6688, 3659, 4269, 950, 461, 12959, 3529, 11912, 7970, 9656, 798, 14401, 3549, 371, 2785, 2675, 15324, 14606, 12698, 14954, 7682, 995, 7266, 4489, 10838, 10854, 6018, 5443, 8286, 8261, 4961, 345, 5923, 9510, 7364, 2320, 4522, 2433, 3592, 5316, 10222, 6877, 4762, 469, 13941, 5046, 7312, 5981, 7859, 10620, 1489, 8948, 4310, 1749, 1969, 5546, 6697, 2897, 4152, 9575, 9902, 1072, 1145, 9209, 11054, 788, 9223, 13951, 5637, 7159, 673, 15559, 9056, 10914, 5676, 6426, 10781, 11300, 9880, 1134, 15596, 7622, 14479, 2630, 7513, 6299, 10505, 7119, 7091, 11703, 13852, 12234, 1103, 414, 12076, 920, 11286, 12329, 3527, 1675, 10771, 8676, 9512, 4707, 3788, 7938, 3899, 12883, 10368, 4210, 10606, 2474, 14600, 4911, 8959, 10818, 6947, 14269, 13219, 7283, 7008, 12783, 2309, 14601, 9454, 11611, 10348, 10047, 11825, 8198, 14664, 3699, 4974, 10051, 10244, 6097, 14571, 7314, 13253, 12742, 4928, 13144, 6723, 12920, 14752, 9257, 443, 10135, 181, 1426, 4165, 11428, 2195, 14484, 8175, 2632, 5846, 7817, 9138, 15508, 14726, 7230, 2073, 15546, 13442, 14347, 11895, 6169, 12778, 11225, 5389, 13311, 5477, 1752, 2621, 3405, 2216, 9876, 6744, 12886, 14453, 697, 2310, 1602, 247, 6522, 9626, 13697, 2194, 12655, 3837, 7610, 4284, 5652, 3440, 13046, 14090, 4417, 11246, 8634, 2684, 8429, 11639, 10150, 3986, 14544, 4931, 14831, 731, 13526, 14371, 171, 9949, 2690, 5861, 10456, 4470, 43, 10338, 3450, 1920, 8666, 7528, 3119, 11386, 5586, 5629, 4292, 12139, 6654, 13901, 2046, 3867, 10182, 81, 5204, 6251, 14189, 9292, 1937, 14321, 5363, 4452, 3720, 3422, 3715, 9828, 5479, 13918, 13626, 5972, 9164, 6875, 9520, 15090, 1716, 4900, 15082, 9344, 10281, 7057, 1272, 9728, 9559, 6631, 4700, 10522, 8418, 6203, 4085, 9873, 4124, 2584, 209, 15413, 2875, 11805, 5964, 8087, 5853, 3510, 2891, 3974, 12122, 14916, 8731, 9412, 6145, 3181, 13019, 1564, 142, 6950, 14904, 6925, 6646, 15385, 7298, 13258, 1332, 10639, 13836, 8849, 4512, 1231, 11489, 10590, 8284, 13159, 757, 13065, 7069, 2485, 7399, 14069, 12961, 13532, 8142, 3910, 12884, 2582, 2001, 8894, 15096, 3232, 12098, 12474, 1225, 13432, 1508, 5647, 12433, 14076, 14572, 12359, 14986, 2929, 4028, 7463, 4753, 2703, 14869, 2738, 15542, 2019, 10370, 7574, 2141, 9345, 3223, 2427, 3176, 1687, 8382, 5631, 12182, 5079, 9786, 570, 2409, 482, 3923, 10272, 1039, 607, 12227, 5551, 4437, 4402, 7767, 15150, 4671, 11765, 9222, 14828, 5139, 856, 3441, 11616, 8456, 9010, 691, 15360, 237, 9514, 1331, 12983, 1064, 4011, 2406, 13254, 7724, 1374, 1750, 966, 9390, 8015, 16, 8244, 4764, 4656, 1956, 2689, 12289, 4526, 4738, 7613, 11875, 2144, 12892, 11032, 11760, 929, 12818, 13715, 11860, 11090, 4262, 2513, 15582, 15417, 471, 15046, 5695, 11727, 10761, 6496, 5270, 5992, 5034, 1947, 6705, 5192, 10034, 1534, 4447, 13302, 4507, 14680, 8423, 10615, 4693, 4372, 8442, 1434, 2721, 7945, 2863, 14195, 1813, 12850, 2761, 604, 2961, 6685, 1672, 5922, 11758, 6219, 1190, 7368, 7109, 57, 12664, 9781, 7568, 3842, 5094, 12613, 11227, 1363, 5687, 2095, 7712, 14924, 912, 458, 8615, 9498, 3507, 1120, 14542, 9081, 11362, 2174, 10313, 10795, 9647, 14903, 3238, 7452, 11656, 8578, 3540, 13276, 666, 9308, 2214, 10385, 9882, 8830, 10792, 7111, 9095, 5442, 4009, 7627, 2276, 9388, 15548, 6567, 4107, 7700, 13571, 669, 10187, 4021, 8534, 8540, 6881, 10079, 11910, 6375, 7889, 9833, 8768, 14405, 2104, 3588, 4992, 5241, 3999, 6193, 8635, 7097, 4854, 2979, 11306, 8103, 6873, 1004, 12058, 4702, 4605, 1182, 10616, 8669, 7933, 12560, 1459, 11779, 3303, 11170, 10882, 5176, 4655, 5490, 390, 3353, 2953, 2867, 2983, 12382, 2367, 12635, 7845, 13074, 6694, 7591, 2287, 12584, 6143, 15588, 12697, 12832, 11833, 8388, 10833, 5493, 4747, 2253, 11212, 852, 11806, 12607, 4347, 7969, 5310, 13498, 1870, 6109, 4112, 13168, 4612, 12542, 4770, 11316, 5569, 5342, 1817, 8226, 8256, 41, 6451, 4272, 12815, 942, 10667, 9925, 4932, 8683, 13111, 4349, 8058, 13294, 8926, 6123, 9337, 6287, 8370, 12312, 7375, 7503, 1683, 7223, 1203, 1207, 9386, 6931, 9416, 9727, 226, 12249, 3858, 953, 11499, 5500, 4345, 15594, 14580, 14448, 5582, 7078, 6255, 1657, 14070, 10365, 10068, 14216, 5178, 427, 4999, 13709, 12725, 7730, 13138, 14559, 9350, 12228, 2370, 1312, 6117, 4401, 6714, 999, 13412, 13181, 11890, 945, 2543, 6164, 3089, 4805, 5824, 9562, 14660, 11804, 9975, 764, 692, 12926, 12129, 2227, 4227, 10734, 15302, 13657, 11234, 5348, 10015, 8841, 6942, 2352, 1763, 7049, 13248, 4674, 10518, 4190, 1483, 8207, 4369, 1247, 9952, 3200, 13205, 91, 9489, 14036, 6912, 14589, 4499, 15289, 7331, 307, 9603, 4838, 13189, 3234, 1520, 330, 7630, 14287, 9098, 11808, 4097, 120, 4068, 2131, 3967, 5256, 4445, 11812, 8307, 12647, 4767, 728, 14179, 955, 11282, 10626, 188, 582, 10190, 1117, 2625, 4880, 168, 12876, 5136, 6378, 2428, 13763, 6649, 3241, 12266, 2257, 9465, 9034, 6733, 356, 2102, 12432, 7909, 5680, 14552, 12561, 2544, 8811, 1858, 5144, 7659, 9567, 186, 857, 8430, 2362, 5087, 455, 14840, 9060, 11723, 1503, 2995, 9020, 12781, 7919, 14245, 9166, 11922, 10503, 6011, 3019, 13593, 3082, 14749, 3352, 12390, 10738, 13215, 2259, 311, 587, 10784, 6814, 9638, 6146, 4147, 2336, 5542, 639, 2536, 7354, 1333, 14107, 7291, 4224, 2044, 5825, 9620, 4059, 3345, 11079, 10494, 13520, 3012, 3793, 15377, 12954, 3648, 6078, 15028, 11315, 7961, 8016, 13245, 14631, 9449, 5659, 14900, 2283, 6558, 2430, 9670, 6840, 15024, 13613, 12768, 6620, 6004, 7113, 12041, 15494, 7259, 1321, 7281, 4662, 14499, 9938, 10737, 842, 4593, 8746, 164, 8855, 3309, 13271, 1448, 12094, 15017, 15393, 2782, 5619, 6406, 14390, 14723, 7067, 6350, 5618, 8454, 4564, 10731, 5073, 5305, 1781, 10411, 5648, 8971, 10061, 9870, 8486, 7752, 10744, 13588, 3767, 7083, 1764, 7446, 12719, 5347, 973, 3136, 7917, 2140, 5733, 12780, 13295, 10460, 675, 5298, 9363, 14066, 3833, 13030, 6267, 3227, 8844, 2925, 4036, 5311, 9667, 11015, 13275, 8925, 1964, 8237, 13896, 449, 14746, 313, 10670, 2333, 2455, 13880, 6833, 8861, 14918, 11961, 13201, 907, 4886, 13282, 1249, 5066, 12871, 15203, 9185, 8219, 14015, 9944, 1277, 102, 10035, 7263, 4875, 10495, 10166, 9589, 10879, 10953, 14348, 7547, 4333, 10358, 12165, 11944, 13357, 601, 12319, 15427, 3273, 7597, 7951, 12300, 3224, 13686, 7763, 8848, 3461, 10428, 462, 10383, 8306, 1560, 4278, 1653, 2078, 15390, 10025, 4768, 3917, 13395, 8910, 13924, 3878, 9843, 6698, 14496, 11700, 234, 7998, 12929, 6180, 6026, 12788, 297, 3117, 1465, 9398, 9859, 14665, 11581, 10755, 2994, 7429, 9550, 991, 11634, 825, 4862, 12491, 5196, 10334, 14038, 5636, 9962, 7807, 703, 11095, 6023, 14262, 11318, 6555, 7406, 9513, 13467, 7911, 9930, 1519, 8660, 6764, 15179, 2608, 7830, 11473, 1737, 439, 13321, 7643, 12003, 13703, 11753, 13186, 15327, 9517, 9054, 14104, 8646, 2413, 11562, 12899, 8814, 10117, 13939, 10775, 15241, 3567, 8528, 6798, 5839, 6077, 0, 11625, 7273, 11277, 3319, 10504, 11894, 12238, 7879, 12211, 14231, 12, 12297, 8887, 11004, 13708, 7415, 3288, 1340, 10654, 14864, 10783, 4595, 810, 3046, 10486, 12641, 14297, 4686, 5299, 15482, 7555, 9801, 2035, 13610, 5968, 11636, 11734, 10279, 14921, 4230, 15161, 11424, 12179, 5300, 14400, 1473, 15595, 5118, 10488, 1492, 4012, 2826, 8223, 14623, 11793, 1098, 4739, 19, 10402, 6307, 4555, 12187, 520, 12711, 12079, 11702, 4281, 12900, 8520, 4030, 8689, 10780, 6389, 1974, 5996, 6444, 7544, 12999, 13985, 3651, 6428, 2861, 3994, 4228, 1893, 8426, 11561, 13841, 15050, 9913, 161, 4668, 7381, 5238, 9919, 4213, 14325, 1466, 11093, 11501, 7348, 7790, 6715, 9790, 254, 7603, 4432, 14742, 12680, 516, 3755, 2398, 12802, 7391, 5282, 11455, 12373, 10822, 11135, 4915, 11982, 5752, 6610, 2042, 11679, 6101, 283, 10167, 8806, 8643, 12002, 5699, 5915, 6025, 14356, 11684, 8064, 12922, 3816, 2116, 12634, 15437, 2598, 2768, 10532, 4502, 4967, 3491, 4927, 14541, 14099, 1791, 12092, 2266, 14174, 10743, 2647, 4070, 2573, 14328, 10077, 9746, 3561, 10398, 7065, 15620, 8178, 304, 5429, 8094, 4745, 4428, 7313, 5050, 5938, 11596, 10173, 4497, 12485, 3892, 5973, 6155, 15457, 10003, 14450, 3611, 665, 14054, 944, 545, 1263, 12240, 15186, 1043, 2443, 14017, 14695, 8334, 2246, 6842, 15460, 3247, 6122, 3407, 1674, 9197, 1214, 734, 1912, 10032, 9804, 7558, 8876, 9862, 5314, 9471, 1936, 3594, 3092, 7344, 10483, 2739, 4666, 8224, 13885, 1437, 11674, 3301, 12924, 8963, 13206, 4119, 2933, 13338, 13380, 3943, 13913, 8343, 14096, 13352, 1163, 1171, 1999, 10308, 10806, 2117, 15435, 1628, 15019, 584, 14422, 13427, 8340, 11978, 14839, 5412, 10878, 4799, 5962, 4826, 2515, 11838, 13476, 8324, 7500, 9488, 10387, 8503, 8518, 12989, 12294, 14355, 9666, 15453, 14676, 10506, 11970, 10539, 7465, 9150, 6574, 2683, 11784, 12559, 8248, 1809, 11329, 5910, 9977, 7278, 12151, 12770, 10487, 8193, 4084, 9712, 3125, 6188, 9713, 10919, 2685, 4540, 3036, 8967, 14808, 3813, 4959, 5724, 1807, 15138, 14317, 6713, 10732, 569, 13636, 865, 13685, 14273, 4637, 9963, 14224, 6465, 12203, 8700, 8724, 8387, 4765, 11953, 15198, 554, 8010, 14784, 5025, 9483, 5753, 9251, 8546, 1836, 13480, 3806, 15269, 14423, 1206, 13212, 11272, 12660, 11363, 9198, 10259, 14242, 1966, 5324, 9191, 7284, 9152, 90, 12877, 1416, 2561, 11584, 4492, 3686, 5894, 6936, 7416, 7688, 12490, 1521, 733, 14799, 1925, 1685, 9396, 6648, 5338, 1690, 3166, 10001, 10593, 5820, 15422, 2902, 7271, 1667, 9850, 5197, 15078, 12043, 6106, 7878, 7228, 12243, 13634, 11154, 5381, 10122, 11688, 5308, 15489, 4171, 6499, 10199, 15552, 13910, 13863, 7339, 6224, 4431, 13174, 11999, 4786, 1154, 6856, 6128, 10393, 10760, 4014, 9434, 4317, 1283, 9683, 11722, 10485, 11566, 11456, 12945, 3382, 2985, 5188, 9029, 9929, 5469, 12096, 3329, 7718, 15023, 4116, 10810, 7997, 4995, 863, 3242, 3324, 13869, 14689, 5106, 222, 15423, 14046, 4697, 868, 3893, 1200, 11532, 14817, 9482, 11759, 13718, 12260, 2349, 4343, 11475, 10623, 4029, 7156, 14500, 11902, 13848, 2103, 15333, 4613, 15268, 11001, 15209, 5884, 12827, 14442, 14340, 7390, 15271, 13106, 12448, 8702, 13586, 13349, 3044, 13730, 15133, 8090, 7556, 6414, 8072, 10916, 1082, 64, 8105, 8655, 8588, 9542, 2894, 7425, 13122, 8934, 15531, 5979, 13578, 13919, 324, 9312, 12882, 14074, 1455, 12536, 13935, 14535, 2156, 2609, 2637, 971, 9760, 1355, 15217, 6508, 11854, 1981, 14615, 2832, 12282, 4064, 1917, 11239, 13546, 10274, 9690, 2007, 1389, 10116, 14461, 4698, 4538, 3330, 6561, 738, 14101, 10796, 15597, 8981, 4976, 2798, 1021, 7221, 13539, 4101, 9714, 13096, 10987, 12519, 10473, 9878, 11990, 10296, 15221, 12409, 616, 13920, 1269, 7434, 7690, 10236, 4104, 5447, 8379, 6603, 10126, 690, 10852, 12663, 2840, 10904, 7184, 12665, 8720, 4330, 1993, 1169, 4731, 6605, 7743, 6599, 3135, 13200, 14772, 13517, 7782, 5670, 8845, 9933, 9708, 11837, 10587, 10941, 4212, 11147, 5770, 5778, 5879, 2161, 7586, 3107, 8402, 4471, 9033, 2792, 10607, 8476, 13826, 11388, 14833, 12067, 9883, 7245, 7250, 9705, 3642, 12068, 3379, 2778, 15144, 15170, 1586, 8319, 2107, 9613, 51, 13012, 4128, 10569, 15218, 4811, 1016, 9474, 11025, 10663, 2197, 2114, 7667, 8713, 11195, 306, 11959, 14512, 6576, 15219, 14394, 8637, 2765, 6577, 14751, 3947, 13057, 9499, 12571, 5332, 2321, 9872, 11479, 1209, 1109, 4255, 10719, 7380, 14478, 155, 12552, 15522, 3915, 13629, 14592, 15114, 15274, 7152, 6965, 2381, 5745, 2395, 12198, 636, 2800, 14521, 13584, 815, 12524, 5484, 10705, 15535, 7424, 6910, 7608, 13293, 12710, 11699, 3938, 5863, 15238, 2498, 14086, 9858, 239, 6184, 11897, 11102, 11395, 5775, 1709, 2786, 8946, 8200, 317, 15516, 4154, 10026, 8541, 4077, 11844, 6464, 11123, 13726, 11934, 4456, 12723, 8828, 9590, 4982, 3700, 10270, 2726, 6217, 2691, 10909, 3074, 7769, 10605, 2038, 10261, 14203, 4178, 5607, 6547, 10955, 14257, 7428, 2252, 14196, 8622, 8416, 8450, 10458, 2812, 1829, 6848, 14042, 7518, 13257, 574, 10779, 13650, 10578, 3797, 9171, 6748, 9693, 10442, 5229, 6858, 230, 2136, 9950, 10132, 7115, 1922, 13672, 4382, 10459, 421, 3070, 15216, 4123, 14988, 407, 3970, 11638, 11655, 2526, 12403, 4525, 14889, 884, 14786, 11002, 968, 7022, 5008, 1496, 11850, 4472, 6811, 3138, 671, 9336, 13472, 5158, 10164, 4543, 6509, 11778, 6855, 13970, 3897, 10045, 12480, 7538, 9099, 9818, 3157, 10466, 12016, 10481, 13561, 4050, 9377, 15488, 13766, 13473, 5572, 885, 11287, 7800, 1239, 9665, 1264, 389, 12746, 15357, 6232, 2565, 8171, 14343, 10965, 8892, 5195, 9619, 406, 8775, 9627, 4163, 11392, 4550, 13382, 12940, 6878, 11884, 6731, 10239, 10571, 9, 3341, 11440, 11816, 6112, 1954, 13014, 14193, 11419, 1780, 2332, 14225, 12396, 4776, 10748, 7583, 12804, 3908, 12795, 4955, 2759, 11848, 15472, 6022, 7141, 10698, 700, 10376, 7451, 12056, 1435, 10618, 13142, 5274, 14640, 5368, 3934, 10422, 4420, 6113, 5983, 11151, 6309, 5265, 10450, 760, 5485, 2150, 3904, 3620, 1682, 2914, 2037, 1446, 13011, 12065, 12492, 3425, 13510, 12685, 5512, 12908, 8348, 9492, 1378, 4998, 14809, 3413, 11880, 6142, 11163, 7759, 12353, 13332, 667, 7753, 3404, 29, 11380, 5416, 5059, 1612, 10282, 819, 10223, 6647, 5243, 8589, 1886, 2796, 2948, 4173, 5227, 14488, 4887, 7270, 1442, 6572, 11407, 13820, 11874, 9618, 12528, 15158, 1806, 1732, 12419, 1513, 10349, 14128, 12160, 9675, 10424, 5842, 7891, 14415, 7739, 2004, 1980, 6511, 7488, 6370, 8095, 13361, 7411, 1527, 5488, 3522, 9225, 7815, 2672, 1511, 11202, 14133, 772, 3871, 6719, 13802, 404, 9587, 8870, 2963, 6262, 8174, 7171, 2879, 15284, 14862, 4488, 14674, 7983, 10354, 11113, 4785, 11569, 3853, 12272, 13912, 4681, 8364, 9526, 11040, 14886, 15611, 13907, 14899, 12585, 6797, 11081, 10933, 3239, 2717, 1867, 8592, 7493, 10233, 2495, 4935, 1605, 4559, 6973, 2020, 12191, 3754, 12633, 8439, 4852, 7534, 9745, 2023, 9946, 6138, 10479, 3349, 668, 5663, 2773, 7437, 12437, 11696, 8889, 6385, 4118, 9583, 5166, 4833, 5016, 3034, 6410, 15089, 12814, 8114, 2911, 1986, 14155, 7393, 12048, 6361, 9964, 12819, 1418, 2178, 9663, 10285, 14020, 3269, 5958, 4239, 7158, 14910, 3064, 3633, 14264, 5356, 7248, 3553, 1342, 14158, 9356, 13482, 5170, 2667, 10314, 9800, 5943, 14683, 4793, 4815, 546, 10374, 9646, 6439, 3446, 11605, 4987, 5445, 6720, 5697, 7703, 11368, 4148, 14659, 15309, 14619, 8266, 12371, 1404, 14239, 14813, 9048, 2101, 13032, 7783, 13157, 1393, 2099, 8638, 11781, 13950, 9313, 3397, 13761, 11066, 13286, 4215, 6348, 7086, 15503, 8625, 1795, 12952, 4508, 9154, 13160, 9785, 14503, 1847, 2719, 2261, 6689, 5074, 6055, 3610, 6944, 3411, 635, 1515, 3655, 12948, 4188, 4670, 9088, 9729, 140, 9005, 3598, 10276, 2547, 7105, 12482, 15585, 5780, 14288, 7197, 15400, 8333, 528, 9183, 8641, 1968, 4106, 3968, 1261, 8162, 10862, 442, 13568, 14709, 8329, 2626, 10840, 12356, 14495, 6703, 7261, 1871, 8717, 3430, 3750, 791, 8394, 364, 14352, 888, 13369, 7954, 4246, 2181, 7802, 6364, 14890, 5261, 3144, 2760, 989, 6677, 5859, 13509, 6879, 1291, 1635, 9881, 5783, 13851, 11248, 4584, 7332, 12687, 9791, 12852, 13204, 13965, 5628, 12740, 2724, 4830, 7325, 14765, 5565, 5762, 4453, 15623, 4809, 3084, 10301, 5345, 9979, 7330, 848, 4169, 6593, 11972, 11092, 6266, 14420, 4867, 4283, 7797, 9133, 3105, 6381, 14369, 8900, 4588, 4958, 7060, 13461, 9156, 14044, 2814, 5319, 2343, 4943, 11436, 5380, 5672, 3420, 5782, 10021, 10465, 298, 8098, 739, 2589, 12715, 9435, 12245, 13184, 4480, 10353, 14165, 1676, 12764, 89, 14780, 7349, 1245, 6029, 3521, 4981, 15183, 7567, 6241, 1882, 4361, 4033, 997, 9581, 14026, 7254, 7043, 4855, 12512, 13942, 3731, 651, 7723, 3033, 660, 5874, 12928, 14034, 2330, 14097, 12038, 10576, 987, 6546, 9260, 2176, 15094, 4109, 6699, 11469, 6542, 5121, 18, 2743, 14426, 2005, 9969, 7009, 15168, 4007, 163, 11387, 493, 6115, 3387, 15331, 10745, 194, 3744, 3488, 8907, 7521, 9338, 13653, 13441, 13776, 5567, 15079, 6263, 3946, 7138, 2435, 14897, 4551, 3205, 3710, 5141, 8852, 2825, 11330, 4001, 2943, 3629, 13390, 8672, 7675, 6602, 6256, 10774, 14537, 1211, 10455, 8823, 2520, 13082, 15245, 3577, 9043, 9106, 9217, 8472, 2878, 2281, 10768, 15102, 5206, 9868, 9787, 13438, 3009, 13645, 3762, 6479, 10144, 10995, 15604, 6769, 13642, 15341, 2653, 2594, 7697, 8843, 11069, 14433, 11705, 14937, 11609, 14545, 8826, 5103, 12812, 7225, 9595, 428, 10371, 3477, 3696, 849, 8400, 11558, 12119, 6683, 3739, 14322, 408, 269, 5531, 10235, 8846, 3103, 7631, 11794, 8024, 12270, 5603, 3286, 10258, 402, 11864, 9563, 15101, 12127, 7275, 8530, 9131, 2555, 15195, 984, 13368, 1659, 4503, 2051, 15056, 6895, 11426, 12170, 4339, 2094, 8572, 6027, 10994, 12087, 4337, 3020, 14047, 7474, 10095, 15316, 8983, 14361, 4424, 3128, 6072, 12007, 6922, 13884, 5276, 2240, 8470, 15147, 10000, 10114, 12123, 9901, 3568, 7990, 4921, 13938, 6832, 2492, 13609, 5836, 1872, 5707, 6536, 9779, 13112, 10986, 2509, 4774, 5658, 8997, 7161, 11771, 386, 10730, 7524, 12074, 10327, 9041, 10297, 13873, 4756, 13125, 12745, 5440, 9301, 7604, 1769, 3884, 5711, 291, 11064, 8023, 14277, 3821, 11442, 2711, 4723, 14332, 12337, 7384, 9280, 9187, 1532, 610, 9397, 7453, 8076, 10886, 11038, 9003, 4018, 11105, 7678, 4314, 11555, 8466, 4045, 3538, 4870, 14358, 245, 12024, 12101, 6166, 11334, 8941, 3492, 9636, 11775, 10931, 12402, 6215, 13837, 14675, 1090, 13669, 14875, 370, 11881, 5028, 12971, 12859, 15396, 6333, 15067, 7207, 13553, 6553, 9244, 1645, 11423, 13507, 15618, 10556, 5747, 15252, 8647, 555, 10227, 15500, 15065, 9551, 14778, 9650, 3123, 7373, 7448, 12627, 7762, 13819, 13663, 8188, 5829, 103, 8840, 3956, 14407, 14291, 7819, 13616, 6430, 5559, 6330, 1794, 3614, 10209, 11337, 1199, 14617, 13192, 10685, 454, 7011, 5286, 14591, 12405, 5069, 8505, 15469, 8583, 6929, 12888, 11357, 7021, 13565, 1160, 11900, 4485, 12840, 1029, 9044, 9151, 1202, 7310, 1114, 1409, 10202, 15389, 769, 12898, 14624, 10480, 15243, 1256, 9649, 5498, 8842, 2725, 2870, 14351, 8690, 10863, 2586, 2844, 3159, 6216, 2279, 9755, 14241, 7122, 14285, 1070, 14274, 2992, 6336, 4232, 1866, 6899, 1282, 14200, 5635, 12210, 3513, 7869, 7873, 5466, 11516, 13954, 3171, 2086, 3996, 8760, 3268, 6987, 7068, 4125, 13410, 8460, 11879, 4945, 13746, 4257, 3630, 6902, 969, 14704, 2388, 2921, 7560, 11041, 8482, 11265, 12962, 4709, 8873, 5438, 3158, 6704, 5002, 79, 3025, 12393, 1747, 8999, 15267, 10252, 4511, 2105, 11748, 2810, 12258, 11226, 1678, 5503, 1014, 7040, 9227, 158, 2154, 12030, 8112, 13062, 5053, 13136, 14663, 4425, 13161, 12452, 13639, 12917, 5917, 12493, 10326, 8222, 2145, 5911, 3193, 928, 14568, 9564, 1552, 4144, 15157, 1084, 6588, 5471, 13213, 12158, 10415, 5765, 348, 7849, 12209, 13757, 8769, 9078, 14110, 7765, 8243, 5617, 12577, 3302, 7054, 844, 5536, 10793, 7683, 13818, 14298, 15556, 11051, 9378, 6270, 6135, 12793, 1369, 104, 618, 534, 1083, 5233, 2982, 6601, 11954, 10224, 13399, 8378, 7075, 4632, 13614, 905, 1714, 10966, 14561, 9911, 1584, 11115, 14650, 7243, 5320, 1639, 5742, 5111, 2821, 4408, 6939, 4354, 626, 10172, 10070, 11301, 5627, 5735, 9641, 4250, 7947, 264, 14857, 2823, 7645, 11142, 536, 7112, 2226, 8032, 11049, 12498, 7168, 11960, 4394, 3680, 12162, 13086, 35, 11962, 4142, 4749, 12990, 6793, 12313, 14411, 5548, 11058, 3208, 10567, 2699, 6854, 8714, 1254, 13529, 14712, 3467, 13099, 10869, 12073, 9050, 3950, 1595, 9481, 12670, 2657, 2986, 8041, 10195, 15054, 4192, 10657, 4196, 10250, 3225, 5343, 6173, 6276, 7323, 13462, 12631, 6716, 2568, 5692, 2999, 8645, 14121, 3679, 11979, 3839, 12901, 7562, 5408, 14952, 1874, 14531, 2084, 13638, 10892, 1198, 5089, 1201, 12792, 5387, 1351, 10020, 1107, 12782, 2163, 2539, 15361, 11138, 14587, 3972, 15473, 15242, 7726, 833, 508, 9904, 7179, 13961, 7642, 15036, 8718, 6308, 821, 10509, 9967, 12040, 5887, 2705, 2350, 15483, 9214, 1281, 10147, 9479, 13305, 2505, 10066, 12946, 7482, 13426, 2753, 13216, 6887, 8816, 1730, 5524, 10960, 3865, 9694, 10345, 14888, 6545, 12503, 2755, 14883, 3787, 341, 8405, 3337, 9546, 2613, 2623, 4114, 8227, 8763, 8269, 8986, 4211, 4978, 11739, 6590, 11339, 2981, 13075, 3215, 4888, 10934, 8187, 15119, 5977, 15303, 724, 3203, 8944, 2121, 6343, 11482, 9233, 3139, 12726, 4784, 2612, 6846, 13633, 9984, 13376, 5006, 11298, 12368, 12457, 4140, 719, 15074, 453, 7781, 15099, 1600, 9273, 10344, 6530, 13854, 12837, 10715, 7412, 12138, 6260, 9228, 2678, 2569, 10988, 88, 2460, 2924, 8755, 1748, 2591, 4322, 11244, 12220, 7208, 3258, 10733, 9772, 3266, 2935, 11024, 7256, 13721, 13533, 6831, 12659, 3940, 12555, 10090, 6074, 11943, 4103, 424, 2361, 8856, 13714, 7648, 903, 12415, 10, 8734, 12986, 2151, 4947, 1224, 4302, 9325, 14387, 1821, 7090, 4327, 1900, 8551, 451, 5955, 1365, 3055, 4145, 15383, 282, 12841, 12113, 1334, 1270, 10240, 3729, 4072, 12028, 5767, 4041, 5230, 441, 12686, 6869, 12843, 8716, 4026, 15386, 12248, 4678, 5014, 350, 7072, 358, 5768, 8369, 6427, 13956, 13725, 12942, 14775, 9102, 1772, 10205, 13185, 11994, 12410, 9793, 13530, 10435, 6089, 1785, 7860, 14915, 3487, 5019, 10911, 1827, 14566, 4589, 1970, 4130, 1921, 11349, 14497, 14147, 9633, 896, 8169, 9765, 11731, 6550, 2996, 13309, 13989, 10484, 10467, 14928, 15306, 2871, 2763, 2837, 5030, 5644, 4199, 14642, 13109, 10918, 14051, 4220, 2458, 6501, 10893, 8600, 14962, 1384, 5961, 10594, 5231, 7632, 9661, 13446, 899, 6124, 10634, 5677, 13465, 4781, 3479, 648, 1087, 14795, 1704, 10136, 12320, 9021, 14805, 15000, 8510, 10118, 13092, 7491, 403, 947, 5751, 13048, 3209, 8759, 875, 6775, 4383, 699, 15549, 8134, 5867, 13890, 479, 12932, 12919, 12499, 15459, 14917, 4377, 3775, 3087, 15367, 7123, 10789, 1863, 224, 11877, 523, 3627, 13152, 4975, 4150, 12721, 7185, 11643, 7833, 9635, 1468, 4271, 3520]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      uid        score  elapsed_time  accuracy\n",
              "14  15495  1681.899780      1.347902    78.224\n",
              "12   1053  1673.244507      1.396110    76.652\n",
              "6    7550  1647.517944      1.290516    79.052\n",
              "13   1367  1643.898071      1.290066    80.192\n",
              "9    7030  1638.099487      1.273251    83.280"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5f4d417-22d6-42a9-8fa6-935d73023f69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>score</th>\n",
              "      <th>elapsed_time</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15495</td>\n",
              "      <td>1681.899780</td>\n",
              "      <td>1.347902</td>\n",
              "      <td>78.224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1053</td>\n",
              "      <td>1673.244507</td>\n",
              "      <td>1.396110</td>\n",
              "      <td>76.652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7550</td>\n",
              "      <td>1647.517944</td>\n",
              "      <td>1.290516</td>\n",
              "      <td>79.052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1367</td>\n",
              "      <td>1643.898071</td>\n",
              "      <td>1.290066</td>\n",
              "      <td>80.192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7030</td>\n",
              "      <td>1638.099487</td>\n",
              "      <td>1.273251</td>\n",
              "      <td>83.280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5f4d417-22d6-42a9-8fa6-935d73023f69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5f4d417-22d6-42a9-8fa6-935d73023f69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5f4d417-22d6-42a9-8fa6-935d73023f69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NaswotREA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hov87k0BUwXP",
        "CW5ewvBLU1OE",
        "C7EkocqlU5P7",
        "kLWrtL3dU7uf",
        "fyQKB2AfZmgc",
        "SdWImgk0VCKr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}